['第9章. 构建我们自己的锁\n', '\n', '在本章中，我们将构建自己的互斥锁、条件变量和读写锁。对于每一种锁，我们将首先从一个非常基础的版本开始，然后扩展它，使之变得更加高效。\n', '\n', '由于我们不打算使用标准库中的锁类型（那样会有作弊的嫌疑），我们将要使用第8章中的工具来使得线程能够在不忙等待的情况下等待。然而，正如我们在那章中看到的，操作系统提供的可用工具在不同平台上有很大的差异，这使得构造跨平台工作的锁变得困难。\n', '\n', '幸运的是，大多数现代操作系统支持类似futex的功能，或者至少支持唤醒和等待操作。正如我们在第8章中看到的，Linux从2003年起通过futex系统调用支持他们，Windows从2012年起通过WaitOnAddress函数家族支持他们，FreeBSD从2016年起作为_umtx_op系统调用的一部分支持他们，等等。\n', '\n', '最值得注意的例外是macOS。尽管其内核的确支持这些操作，但它并没有通过任何稳定的、公开可用的、我们可以使用的C函数进行暴露。然而，macOS确实随附了一个最近版本的libc++，这是一个C++标准库的实现。这个库包含对C++20的支持，这个版本的C++中带有基本的原子等待和唤醒操作的内置支持（比如std::atomic<T>::wait()）。虽然由于各种原因从Rust中使用这个功能有些棘手，但肯定是可行的，这也使我们能够在macOS上获取基本的类似futex的等待和唤醒功能。\n', '\n', '我们不会深入推论这些复杂的细节，而是使用来自crates.io的atomic-wait库，为我们的锁定原语提供构建块。此库只提供三个函数：wait()，wake_one()，和wake_all()。它对所有主要的平台进行了实现，使用了我们上面讨论过的各种特定平台的实现。这意味着我们无需再考虑任何与平台相关的细节，只要我们坚持使用这三个函数。\n', '\n', '这些函数的行为就像我们在第8章的“Futex”一节中为Linux实现的同名函数，但让我们快速回忆一下它们是如何工作的：\n', '\n', 'wait(&AtomicU32, u32)\n', '\n', '    此函数用于等待，直到原子变量不再包含给定的值。如果原子变量中存储的值等于给定的值，它就会阻塞。当另一个线程修改原子变量的值时，该线程需要调用下面的其中一个唤醒函数，对同一个原子变量进行操作，以唤醒等待的线程。\n', '\n', '    该函数可能会在没有相应的唤醒操作的情况下返回，所以在它返回后一定要检查原子变量的值，并在必要时重复调用wait()函数。\n', 'wake_one(&AtomicU32)\n', '\n', '    这将唤醒一个正在在同一个原子变量上等待的线程。在修改原子变量之后立即使用此函数，以通知一个等待线程的改变。\n', 'wake_all(&AtomicU32)\n', '\n', '    这将唤醒所有当前正在在同一个原子变量上等待的线程。在修改原子变量后立即使用此函数，以通知所有等待的线程进行改变。\n', '\n', '只有32位原子变量被支持，因为这是所有主要平台都支持的唯一大小。\n', '\n', '在第8章的“Futex”中，我们讨论了一个非常小的例子，该例子展示了如何在实践中使用这些函数。如果你忘记了，请在继续之前查看那个例子。\n', '\n', '要使用atomic-wait库，在你的Cargo.toml的[dependencies]区域中添加atomic-wait = "1"；或者运行cargo add atomic-wait@1，这将帮你完成。这三个函数是在库的根目录下定义的，可以通过use atomic_wait::{wait, wake_one, wake_all};进行导入。\n', '\n', '可能在你阅读这个时，该库有了更新的版本，但只有大版本1是为这一章准备的。后续版本可能不具有兼容的接口。\n', '\n', '现在我们有了基本的构建块，让我们开始吧。\n', '互斥锁\n', '\n', '我们将在构建我们的Mutex<T>时，将第4章中的SpinLock<T>类型作为我们的参照。那些不涉及阻塞的部分，比如守护类型的设计，将保持不变。\n', '\n', '让我们从类型定义开始。我们需要相较于自旋锁作出一个改变：我们将使用一个AtomicU32，设定为零或一，而不是一个AtomicBool设定为假或真，这样我们就可以用它来使用原子等待和唤醒函数。\n', '\n', 'pub struct Mutex<T> {\n', '    /// 0: 解锁\n', '    /// 1: 锁定\n', '    state: AtomicU32,\n', '    value: UnsafeCell<T>,\n', '}\n', '\n', '就像对自旋锁一样，我们需要承诺Mutex<T>可以在线程之间共享，即使它包含一个可怕的UnsafeCell：\n', '\n', 'unsafe impl<T> Sync for Mutex<T> where T: Send {}\n', '\n', '我们还将添加一个实现了Deref特性的MutexGuard类型，就像我们在第4章的“A Safe Interface Using a Lock Guard”中所做的那样，以提供一个完全安全的锁定接口：\n', '\n', "pub struct MutexGuard<'a, T> {\n", "    mutex: &'a Mutex<T>,\n", '}\n', '\n', "impl<T> Deref for MutexGuard<'_, T> {\n", '    type Target = T;\n', '    fn deref(&self) -> &T {\n', '        unsafe { &*self.mutex.value.get() }\n', '    }\n', '}\n', '\n', "impl<T> DerefMut for MutexGuard<'_, T> {\n", '    fn deref_mut(&mut self) -> &mut T {\n', '        unsafe { &mut *self.mutex.value.get() }\n', '    }\n', '}\n', '\n', '对于锁守护类型的设计和操作，见第4章的“A Safe Interface Using a Lock Guard”。\n', '\n', '在我们继续之前，让我们处理好Mutex::new函数。\n', '\n', 'impl<T> Mutex<T> {\n', '    pub const fn new(value: T) -> Self {\n', '        Self {\n', '            state: AtomicU32::new(0), // 解锁状态\n', '            value: UnsafeCell::new(value),\n', '        }\n', '    }\n', '\n', '    …\n', '}\n', '\n', '现在我们已经处理完了所有那些，还剩下两个部分：锁定（Mutex::lock()）和解锁（对MutexGuard<T>的Drop操作）。\n', '\n', '我们为我们的自旋锁实现的锁定功能使用了一个原子交换操作来尝试获取锁，如果成功地从"解锁"状态切换到"锁定"状态，它就返回。如果失败，它立即再试。\n', '\n', '要锁定我们的互斥锁，我们将做几乎相同的事情，除了我们使用wait()等待再试一次：\n', '\n', '    pub fn lock(&self) -> MutexGuard<T> {\n', '        // 将状态设定为 1: 锁定。\n', '        while self.state.swap(1, Acquire) == 1 {\n', '            // 如果已经被锁定..\n', '            // .. 等待，除非状态不再是 1。\n', '            wait(&self.state, 1);\n', '        }\n', '        MutexGuard { mutex: self }\n'][' }\n', '\n', '对于内存排序，使用与我们的自旋锁相同的推理逻辑。可以参考第4章的详细内容。\n', '\n', '注意wait()函数仅在我们调用该函数时的状态仍然设置为1（锁定）时才会阻塞，这样我们就不必担心在交换和等待调用之间可能错过唤醒调用的可能性。\n', '\n', 'guard类型的Drop实现负责解锁互斥锁。解锁我们的自旋锁很简单：只需将状态重新设置为false（解锁）。然而，对于我们的互斥锁来说，这还不够。如果有线程等待锁定互斥锁，它不知道互斥锁已经解锁，除非我们使用唤醒操作通知它。如果我们不唤醒它，它很可能会永远保持睡眠。（也许这是幸运的，可能会在正确的时间突然被唤醒，但让我们不要指望这一点。）\n', '\n', '所以，我们不仅将状态重新设置为0（解锁），而且还会在之后立即调用wake_one():\n', '\n', "impl<T> Drop for MutexGuard<'_, T> {\n", '    fn drop(&mut self) {\n', '        //将状态重新设置为0：解锁。\n', '        self.mutex.state.store(0, Release);\n', '        //唤醒一个等待的线程，如果有的话。\n', '        wake_one(&self.mutex.state);\n', '    }\n', '}\n', '\n', '唤醒一个线程就足够了，因为即使有多个线程在等待，也只有其中一个能够请求到锁。下一个获取到锁的线程完成后会唤醒另一个线程，依此类推。同时唤醒多个线程只会使这些线程感到失望，当他们中的大多数意识到锁定的机会被另一个幸运的线程抢走了，他们又要重新睡觉，这会浪费宝贵的处理器时间。\n', '\n', '注意，我们无法保证唤醒的线程能够获取到锁。另一个线程可能会在它有机会之前抢占到锁。\n', '\n', '这里要强调的一点是，如果没有等待和唤醒函数，这个互斥锁的实现仍然是技术上正确的（也就是说，内存安全）。因为wait()操作可能会无故地唤醒，我们无法对它返回时的情况做出任何假设。我们仍然需要自己管理我们的锁定基元的状态。如果我们去掉等待和唤醒函数的调用，我们的互斥锁基本上就变成了我们的自旋锁。\n', '\n', '一般而言，从内存安全的角度来看，原子等待和唤醒函数从不影响正确性。它们只是避免忙等待的一种（非常严重的）优化。这并不意味着一个无法有效使用的低效的锁会被任何实用标准认为是"正确的"，但这个观点在试图理解不安全的Rust代码时可能会有帮助。\n', 'Lock API\n', '\n', '如果你计划把实现Rust锁当做新的爱好，你可能会很快对提供一个安全接口所涉及的样板代码感到厌倦。也就是说，UnsafeCell，Sync的实现，guard类型，Deref的实现等等。\n', '\n', '可以在crates.io上找到lock_api包来自动处理所有的事情。只需创建一个表示锁的状态的类型，并通过(unsafe)lock_api::RawMutex特性提供(unsafe)的锁和解锁函数。作为回报，lock_api::Mutex类型将基于您的锁实现为您提供一个完全安全和人体工程学的互斥锁类型，包括一个互斥锁守护器。\n', '避免系统调用\n', '\n', '我们的互斥锁中最慢的部分就是等待和唤醒操作，因为它们可能导致系统调用，也就是调用操作系统的内核。像这样与内核交谈是一个相当复杂的过程，比原子操作慢得多。因此，对于高性能的互斥锁实现，我们应该尽量避免等待和唤醒调用。\n', '\n', '幸运的是，我们已经过半了。因为我们的锁定功能中的while循环在等待()调用之前检查了状态，所以在不需要等待的情况下，当互斥锁不被锁定时，完全跳过了等待操作。然而，我们在解锁时无条件地调用wake_one()函数。\n', '\n', '如果我们知道没有其他线程在等待，我们可以跳过wake_one()。为了知道是否有等待的线程，我们需要自己跟踪这些信息。\n', '\n', '我们可以通过将"锁定"状态分为两个独立的状态来做到这一点："既未锁定也无等待者"和"已锁定且有等待者"。对于这两个状态，我们分别使用1和2的值，并更新结构定义中状态字段的文档注释：\n', '\n', 'pub struct Mutex<T> {\n', '    /// 0: 未锁定\n', '    /// 1: 已锁定，没有其他线程在等待\n', '    /// 2: 已锁定，其他线程在等待\n', '    state: AtomicU32,\n', '    value: UnsafeCell<T>,\n', '}\n', '\n', '现在，对于一个未锁定的互斥锁，我们的锁函数仍然需要将状态设置为1来锁定它。然而，如果它已经被锁定了，我们的锁函数就需要在休眠之前将状态设置为2，以便解锁函数能知道有一个等待的线程。\n', '\n', '为此，我们首先使用一个比较和交换函数试图将状态从0改为1。如果成功，我们就锁定了互斥锁，并且知道没有其他的等待者，因为这个互斥锁之前并没有被锁定。如果失败，那一定是因为互斥锁当前被锁定(状态为1或2)。在这种情况下，我们将使用一个原子交换操作将其设置为2。如果那个交换操作返回一个旧值为1或者2，那就意味着互斥锁的确仍然是锁定的，我们就只有在等待()之后才能阻断它改变。如果交换操作返回0，那就意味着我们通过将其状态从0改为2成功地锁定了互斥锁。\n', '\n', '    pub fn lock(&self) -> MutexGuard<T> {\n', '        if self.state.compare_exchange(0, 1, Acquire, Relaxed).is_err() {\n', '            while self.state.swap(2, Acquire) != 0 {\n', '                wait(&self.state, 2);\n', '            }\n', '        }\n', '        MutexGuard { mutex: self }\n', '    }\n', '\n', '现在，我们的解锁函数可以利用这个新的信息，当没必要的时候跳过唤醒一个线程的调用。我们不再仅仅将0存储以解锁互斥锁，我们现在使用一个交换操作，以便我们能检查出它以前的值。只有在该值为2时，我们才继续唤醒一个线程：\n', '\n', "impl<T> Drop for MutexGuard<'_, T> {\n", '    fn drop(&mut self) {\n', '        if self.mutex.state.swap(0, Release) == 2 {\n', '            wake_one(&self.mutex.state);\n', '        }\n', '    }\n', '}\n', '\n', '注意，在状态被设置回零之后，它不再表示是否还有任何等待的线程。被唤醒的线程负责将状态设置回2，以确保其他等待的线程不会被遗忘。这就是为什么比较和交换操作不是我们锁函数中while循环的一部分。\n', '\n', '这意味着，对于每一次一个线程在锁定时，都要等待()，它也会在解锁时调用wake_one()，即使不必要。然而，最重要的是，在无竞争的情况下，即理想情况下，线程不尝试同时获取锁，wait()和wake_one()的调用会被完全避免。\n', '\n', '图9-1显示了两个并发尝试锁定我们互斥锁的线程中操作和发生在先前关系的情况。第一个线程通过将状态从0变为1锁定互斥锁。在那点，第二个线程将无法获取锁，并因此在将状态从1变为2后进入睡眠状态。当第一个线程解锁Mutex时，它将状态交换回0。因为它是2，表示有一个等待的线程，所以它调用wake_one()来唤醒第二个线程。注意我们并不依赖于唤醒和等待操作之间的任何happens-before关系。虽然唤醒操作很可能是唤醒等待线程的那个线程，但是happens-before关系是通过acquire swap操作观察到release swap操作存储的值来建立的。\n', '图9-1. 两个线程并发尝试锁定我们的互斥锁时发生的事情。图片说明\n', '进一步优化\n', '\n', '在这一点上，可能看起来我们没有多少可以进一步优化的地方。在无竞争的情况下，我们执行了零次系统调用，仅余下了两个非常简单的原子操作。\n', '\n', '避免等待和唤醒操作的唯一方法是回到我们的自旋锁实现。尽管自旋通常非常低效，但它至少能避免潜在的系统调用开销。唯一自旋可能更高效的情况是只等待很短的时间。\n', '\n', '对于锁定互斥锁，这只发生在当前持有锁的线程在不同的处理器核上并行运行，并且只短暂地保持锁的情况。然而，这是一个很常见的情况。\n', '\n', '我们可以尝试通过在调用wait()之前稍微自旋一阵子，然后再回到两种方法的最佳部分。这样，如果锁很快被释放，我们就不需要调用wait()，但我们仍然避免消耗过多的处理器时间，其他线程可以更好地利用这些时间。\n', '\n', '实现这个只需要修改我们的锁函数。\n', '\n', '为了在无竞争的情况下尽可能保持高性能，我们将保留锁定函数开始时的原始比较和交换操作。我们将无聊的等待留给一个单独的函数。\n', '\n', 'impl<T> Mutex<T> {\n', '    ...\n', '\n', '    pub fn lock(&self) -> MutexGuard<T> {\n', '        if self.state.compare_exchange(0, 1, Acquire, Relaxed).is_err() {\n', '            //锁已经被锁上了。:(\n', '            lock_contended(&self.state);\n', '        }\n']
['        MutexGuard { mutex: self }\n', '    }\n', '}\n', '\n', 'fn lock_contended(state: &AtomicU32) {\n', '    …\n', '}\n', '\n', '在lock_contended中，我们可以简单地重复进行几百次比较和交换操作，然后继续进入等待循环。然而，比较和交换操作通常试图获得对相关缓存行的独占访问权（参见第7章的"关于MESI协议"），如果反复执行，它会比简单的加载操作更加昂贵。\n', '\n', '考虑到这一点，我们来进行以下的lock_contended实现：\n', '\n', 'fn lock_contended(state: &AtomicU32) {\n', '    let mut spin_count = 0;\n', '\n', '    while state.load(Relaxed) == 1 && spin_count < 100 {\n', '        spin_count += 1;\n', '        std::hint::spin_loop();\n', '    }\n', '\n', '    if state.compare_exchange(0, 1, Acquire, Relaxed).is_ok() {\n', '        return;\n', '    }\n', '\n', '    while state.swap(2, Acquire) != 0 {\n', '        wait(state, 2);\n', '    }\n', '}\n', '\n', '首先，我们最多旋转100次，像我们在第4章那样使用旋转循环提示。我们只有在互斥锁被锁定且没有等待者时才旋转。如果另一个线程已经在等待，这意味着它放弃旋转，因为这花费了太长时间，这可能表明对这个线程来说，旋转可能不会很有用。\n', '\n', '一个百次的旋转持续时间基本上是随意选择的。每次迭代所花费的时间和系统调用的持续时间（我们试图避免的）在很大程度上依赖于平台。通过广泛的基准测试可以帮助选择正确的数字，但不幸的是，没有一个单一的正确答案。\n', '\n', 'Rust标准库中std::sync::Mutex的Linux实现，至少在Rust 1.66.0中，使用的是100次旋转。\n', '\n', '锁状态改变后，我们再尝试一次通过设置为1来锁定它，然后我们放弃并开始等待。如我们之前讨论的，调用wait()后，我们不能再通过设置其状态为1来锁定互斥锁，因为这可能导致其他等待者被遗忘。\n', '冷和内联属性\n', '\n', '你可以将#[cold]属性添加到lock_contended函数定义，帮助编译器理解这个函数在普通（无争用）情况下并不会被调用，这可以帮助对lock方法进行优化。\n', '\n', '此外，你可以将#[inline]属性添加到Mutex和MutexGuard方法，通知编译器将它们内联可能是一个好主意：将生成的指令直接放在调用方法的地方。一般来说，这是否能提高性能是很难说的，但对于这样的小函数，通常是可以的。\n', '基准测试\n', '\n', '测试互斥锁实现的性能是困难的。编写基准测试并获得一些数字很容易，但获得有意义的数字非常困难。\n', '\n', '优化互斥锁实现以在特定基准测试中表现非常好相对较易， but not very useful. After all, the point is to make something that performs well in real-world programs, not just in test programs.\n', '\n', '我们将试图编写两个简单的基准测试，展示我们的优化至少对一些用例有些积极的影响，但请记住，任何结论在不同的情况下都可能不会成立。\n', '\n', '对于我们的第一个测试，我们会创建一个互斥锁，并锁定和解锁它几百万次，全部在同一线程上，测量总时间。这是一个琐碎的无争用场景测试，其中从来没有任何线程需要被唤醒。我们希望，这将向我们展示2状态和3状态版本之间的显著差异。\n', '\n', 'fn main() {\n', '    let m = Mutex::new(0);\n', '    std::hint::black_box(&m);\n', '    let start = Instant::now();\n', '    for _ in 0..5_000_000 {\n', '        *m.lock() += 1;\n', '    }\n', '    let duration = start.elapsed();\n', '    println!("locked {} times in {:?}", *m.lock(), duration);\n', '}\n', '\n', '我们使用std::hint::black_box（就像我们在第7章的"对性能的影响"中所做的那样）来强制编译器假设可能有更多的代码访问互斥锁，防止它优化掉循环或锁定操作。\n', '\n', '结果将严重依赖硬件和操作系统。在一台配备最近的AMD处理器的Linux电脑上尝试这个，我们未优化的2状态互斥锁的总时间约为400毫秒，而我们更优化的3状态互斥锁约为40毫秒。提升了十倍！在另一台配备较旧的Intel处理器的Linux电脑上，差异更大：约1800毫秒对60毫秒。这证实了添加第三状态确实可以是一个非常重要的优化。\n', '\n', '然而，在运行macOS的电脑上运行这个，产生了完全不同的结果：两个版本都是约50毫秒，显示这完全取决于平台。\n', '\n', '事实证明，我们在macOS上使用的libc++的std::atomic<T>::wake()的实现，已经执行了自己的记录，独立于内核，以避免不必要的系统调用。Windows上的WakeByAddressSingle()也是如此。\n', '\n', '避免调用这些函数仍然可以有稍微更好的性能，因为它们的实现远非易事，尤其是因为它们不能在原子变量本身存储任何信息。但是，如果我们只针对这些操作系统，我们应该质疑为我们的互斥锁添加第三状态是否值得。\n', '\n', '要看我们的旋转优化是否有任何积极的影响，我们需要一个不同的基准测试：一个有大量争用的，多个线程反复试图锁定一个已被锁定的互斥锁。\n', '\n', '我们试一下四个线程同时尝试锁定和解锁互斥锁几百万次的场景：\n', '\n', 'fn main() {\n', '    let m = Mutex::new(0);\n', '    std::hint::black_box(&m);\n', '    let start = Instant::now();\n', '    thread::scope(|s| {\n', '        for _ in 0..4 {\n', '            s.spawn(|| {\n', '                for _ in 0..5_000_000 {\n', '                    *m.lock() += 1;\n', '                }\n', '            });\n', '        }\n', '    });\n', '    let duration = start.elapsed();\n', '    println!("locked {} times in {:?}", *m.lock(), duration);\n', '}\n', '\n', '注意这是一个极端和不切实际的场景。互斥锁仅保持了极短的时间（只增加了一个整数），并且线程在解锁后立即再次尝试锁定互斥锁。不同的场景可能会导致非常不同的结果。\n', '\n', '让我们在之前同样的两台Linux电脑上运行这个基准测试。在较老的Intel处理器的电脑上，没有旋转的版本的互斥锁大约需要900毫秒，而使用旋转版本需要约750毫秒。进步了！然而，在配备新型AMD处理器的电脑上，我们得到相反的结果：大约650毫秒没有旋转，大约800毫秒有旋转。\n', '\n', '所以，旋转是否真的提高性能的答案，不幸地是，"这取决于具体情况"，即使只看一个场景。\n', '条件变量\n', '\n']['让我们转向更有乐趣的事情：实现一个条件变量。\n', '\n', '正如我们在第1章的“条件变量”中所看到的，条件变量与互斥锁一起使用，以等待互斥锁保护的数据满足某个条件。它具有一个等待方法，这个方法会解锁一个互斥锁，等待一个信号，然后再次锁定相同的互斥锁。信号由其他线程发送，通常在修改了互斥锁保护的数据之后立即发送到等待的线程（通常被称为“通知一个”或“信号”）或所有等待的线程（通常被称为“通知所有人”或“广播”）。\n', '\n', '虽然条件变量试图保持一个等待线程在被信号唤醒之前一直处于睡眠状态，但是一个等待线程可能会在没有对应信号的情况下被唤醒，这就是假唤醒。但是，条件变量的等待操作仍然会在返回之前重新锁定互斥锁。\n', '\n', '注意这个接口几乎与我们的futex风格的wait()、wake_one()和wake_all()函数完全相同。主要的区别是用于防止丢失信号的机制。在解锁互斥锁之前，一个条件变量会开始“监听”信号，以防错过之后的任何信号，而我们的futex风格的wait()函数则依赖于检查原子变量的状态，以确保等待仍然是一个好主意。\n', '\n', '这就导致了一个条件变量的最小实现思路：如果我们确保每个通知都改变了一个原子变量（比如计数器），那么我们的Condvar::wait()方法需要做的就是在解锁互斥锁之前检查该变量的值，并在解锁后将其传递给futex风格的wait()函数。这样，如果在解锁互斥锁之后有任何通知信号到达，它就不会进入睡眠状态。\n', '\n', '我们来试试看！\n', '\n', '我们首先定义一个只包含一个AtomicU32的Condvar结构，我们将其初始化为零：\n', '\n', 'pub struct Condvar {\n', '    counter: AtomicU32,\n', '}\n', '\n', 'impl Condvar {\n', '    pub const fn new() -> Self {\n', '        Self { counter: AtomicU32::new(0) }\n', '    }\n', '\n', '    …\n', '}\n', '\n', 'notify方法很简单。它们只需要改变计数器，并使用相应的wake操作来通知任何等待的线程：\n', '\n', '    pub fn notify_one(&self) {\n', '        self.counter.fetch_add(1, Relaxed);\n', '        wake_one(&self.counter);\n', '    }\n', '\n', '    pub fn notify_all(&self) {\n', '        self.counter.fetch_add(1, Relaxed);\n', '        wake_all(&self.counter);\n', '    }\n', '\n', '（我们稍后会讨论内存顺序。）\n', '\n', 'wait方法将接受一个MutexGuard，因为这代表了一个锁定的互斥锁的证明。它还会返回一个MutexGuard，因为它会确保互斥锁在返回之前被再次锁定。\n', '\n', '正如我们上面提到的，这个方法首先会在解锁互斥锁之前检查计数器的当前值。在解锁互斥锁后，如果计数器没有变化，它应该只是等待，以确保我们没有错过任何信号。以下是代码的样子：\n', '\n', "    pub fn wait<'a, T>(&self, guard: MutexGuard<'a, T>) -> MutexGuard<'a, T> {\n", '        let counter_value = self.counter.load(Relaxed);\n', '\n', '        // 解锁互斥锁需要放弃Guard，\n', '        // 但是要记住互斥锁，以便我们以后能再锁定它。\n', '        let mutex = guard.mutex;\n', '        drop(guard);\n', '\n', "        // 等待，但只有在计数器在解锁后没有变化的情况下才等待。\n", '        wait(&self.counter, counter_value);\n', '\n', '        mutex.lock()\n', '    }\n', '\n', '这利用了MutexGuard的私有互斥锁字段。Rust的隐私基于模块，所以如果你在MutexGuard之外的其他模块中定义这个，你需要将MutexGuard的互斥锁字段标记为例如pub(crate)以使其对包中的其他模块可用。\n', '\n', '在我们庆祝成功完成条件变量的实现之前，让我们花一点时间思考下内存顺序。\n', '\n', '当互斥锁被锁定时，没有其他线程可以改变互斥锁保护的数据。因此，我们不需要担心在解锁互斥锁之前的通知，因为只要我们保持互斥锁被锁定，就不会有任何事情发生，会让我们改变对是否想要睡眠和等待的想法。\n', '\n', '我们感兴趣的唯一情况是，当我们释放互斥锁后，另一个线程过来并锁定互斥锁，改变被保护的数据，并向我们发出信号（希望在解锁互斥锁后）。\n', '\n', '在这种情况下，Condvar::wait()中解锁互斥锁和通知线程中锁定互斥锁之间存在一种happens-before关系。这种happens-before关系保证了我们的relaxed load，它在解锁之前发生，将观察到在通知的relaxed increment操作之前的值，后者在锁定之后发生。\n', '\n', '我们不知道wait()操作会在加值之前还是之后看到值，因为在那个时点没有任何东西保证任何的顺序。然而，这并不重要，因为wait()与对应的wake操作的行为是原子的。要么它看到新的值，这种情况下它根本不会进入睡眠状态，要么它看到旧的值，这种情况下它会进入睡眠，并会被通知中的wake_one()或wake_all()唤醒。\n', '\n', '图9-2显示了一个线程使用Condvar::wait()等待一些互斥锁保护的数据变化并被第二个线程唤醒，这个线程修改数据并调用Condvar::wake_one()的操作和happens-before关系。注意第一个load操作在加值之前观察的值是有保证的，多亏了解锁和锁定操作。\n', '图9-2. 一个线程使用Condvar::wait()等待，另一个线程使用Condvar::notify_one()唤醒了它，这里展示了操作和happens-before关系的描述。\n', '\n', '我们还应该考虑计数器溢出的情况。\n', '\n', '计数器的实际值并不重要，只要它在每次通知后都有所不同。不幸的是，经过四十多亿次通知后，计数器将溢出并从零开始，回到以前使用过的值。技术上，我们的Condvar::wait()实现可能会在不应该进入睡眠的时候进入睡眠：如果它错过了刚好4294967296个通知（或者任何倍数），它就会将计数器溢出到之前的值。\n', '\n', '完全有理由认为发生这种情况的概率是可以忽略不计的。与我们在互斥锁锁定方法中所做的不同，我们不会在唤醒后重新检查状态并重复wait()调用，所以我们只需要担心在relaxed load计数器和wait()调用之间的瞬间发生溢出回环。如果一个线程能被中断那么长时间，以至于允许发生(恰好)那么多次通知，那么可能已经有一些事情出错了，程序已经变得无响应。在这一点上，可能会有人合理地争论，一个微小的额外风险线程仍然处于睡眠状态已经无关紧要。\n', '\n', '在支持限时等待的平台上，可以通过为等待操作设置几秒钟的超时来减小溢出的风险。发送四十多亿个通知将会花费更长的时间，此时几秒钟的额外风险影响非常小。这完全消除了由于等待线程错误地永远保持睡眠状态导致程序锁定的任何风险。\n', '\n', '让我们看看它是否有效！\n', '\n', '#[test]\n', 'fn test_condvar() {\n', '    let mutex = Mutex::new(0);\n', '    let condvar = Condvar::new();\n', '\n', '    let mut wakeups = 0;\n', '\n', '    thread::scope(|s| {\n', '        s.spawn(|| {\n', '            thread::sleep(Duration::from_secs(1));\n', '            *mutex.lock() = 123;\n', '            condvar.notify_one();\n', '        });\n', '\n', '        let mut m = mutex.lock();\n', '        while *m < 100 {\n', '            m = condvar.wait(m);\n']['            wakeups += 1;\n', '        }\n', '\n', '        assert_eq!(*m, 123);\n', '    });\n', '\n', '    // 检查主线程确实等待（而非忙循环），\n', '    // 同时仍然允许少数偶发的唤醒。\n', '    assert!(wakeups < 10);\n', '}\n', '\n', '我们统计条件变量从它的等待方法返回的次数，以确认它确实已经进入睡眠状态。如果这个数量非常高，那可能就意味着我们在无意中进行旋转循环(spining loop)。这是一个重要的测试，因为即使一个从不睡眠的条件变量也会产生“正确的”行为，但实际上会把等待循环变成一个旋转循环。\n', '\n', '如果我们运行这个测试，可以看到它成功编译并通过，也就确认了我们的条件变量实际上确实使主线程进入睡眠状态。当然，这并不能证明其实现是正确的。一个涉及许多线程的长时间压力测试，理想情况下在一个弱排序处理器架构的计算机上运行，如果有必要，可以用来增加我们的信心。\n', '避免系统调用\n', '\n', '正如我们在"互斥锁：避免系统调用"中所了解到的，优化一个锁定原语主要就是避免不必要的等待和唤醒操作。\n', '\n', '在我们的条件变量的例子中，试图避免我们在Condvar::wait()实现中的wait()调用可能没有多大意义。当一个线程决定等待一个条件变量时，它已经检查过它正在等待的对象还未发生，所以需要进入睡眠状态。如果wait不需要的话，那么它本来就不会调用Condvar::wait()。\n', '\n', '然而，我们可以避免在没有等待的线程时进行wake_one()和wake_all()调用，这与我们对Mutex所做的类似。\n', '\n', '一种实现这个的简单方式就是跟踪等待的线程数量。在等待时，我们的wait方法需要把这个数值增加，然后在完成时减少。然后我们的通知方法在该数值为零时可以跳过发送信号。\n', '\n', '所以，我们在Condvar结构中增加一个新字段来追踪活动等待器的数量：\n', '\n', 'pub struct Condvar {\n', '    counter: AtomicU32,\n', '    num_waiters: AtomicUsize, // 新增!\n', '}\n', '\n', 'impl Condvar {\n', '    pub const fn new() -> Self {\n', '        Self {\n', '            counter: AtomicU32::new(0),\n', '            num_waiters: AtomicUsize::new(0), // 新增!\n', '        }\n', '    }\n', '\n', '    …\n', '}\n', '\n', '通过使用AtomicUsize作为num_waiters，我们不必担心它溢出。usize足以计数内存中的每个字节，所以如果我们假设每个活动线程至少占用一个内存字节，那么它肯定足以计算任何数量的并发存在的线程。\n', '\n', '接下来，我们更新我们的通知函数，如果没有等待者则不做任何事情：\n', '\n', '    pub fn notify_one(&self) {\n', '        if self.num_waiters.load(Relaxed) > 0 { // 新增!\n', '            self.counter.fetch_add(1, Relaxed);\n', '            wake_one(&self.counter);\n', '        }\n', '    }\n', '\n', '    pub fn notify_all(&self) {\n', '        if self.num_waiters.load(Relaxed) > 0 { // 新增!\n', '            self.counter.fetch_add(1, Relaxed);\n', '            wake_all(&self.counter);\n', '        }\n', '    }\n', '\n', '(我们会在一会儿讨论内存排序。)\n', '\n', '最后，最重要的是，我们在wait方法开始时增加它，并在唤醒时立即减少它：\n', '\n', "    pub fn wait<'a, T>(&self, guard: MutexGuard<'a, T>) -> MutexGuard<'a, T> {\n", '        self.num_waiters.fetch_add(1, Relaxed); // 新增!\n', '\n', '        let counter_value = self.counter.load(Relaxed);\n', '\n', '        let mutex = guard.mutex;\n', '        drop(guard);\n', '\n', '        wait(&self.counter, counter_value);\n', '\n', '        self.num_waiters.fetch_sub(1, Relaxed); // 新增!\n', '\n', '        mutex.lock()\n', '    }\n', '\n', '我们再次应该仔细问自己，对于所有这些原子操作，松散的内存排序是否足够。\n', '\n', '我们新引入的一个潜在风险是，notify方法在num_waiters中看到零，跳过其唤醒操作，而实际上存在待唤醒的线程。这可能发生在notify方法在递增操作之前或在递减操作之后看到的值。\n', '\n', '就像从counter中松散加载一样，等待者在递增num_waiters时仍然保持了互斥锁的锁定，这确保任何在解锁互斥锁后发生的num_waiters的加载都不会看到它的递增之前的值。\n', '\n', '我们也不需要担心通知线程“过早”地看到递减值，因为一旦执行了递减操作，也许产生了一个偶发的唤醒，等待的线程根本不需要再被唤醒。\n', '\n', '换句话说，互斥锁建立的happens-before关系仍然提供了我们需要的所有保证。\n', '避免偶发唤醒\n', '\n', '我们优化条件变量的另一种方式是避免偶发唤醒。每次线程被唤醒，它都会尝试锁定互斥锁，可能与其他线程竞争，这可能对性能有大影响。\n', '\n', '底层的wait()操作偶发唤醒的可能性相当低，但是我们的条件变量实现很容易让notify_one()导致多于一个线程停止等待。如果一个线程正在进入睡眠状态，刚刚加载了counter值，但还没有进入睡眠状态，那么调用notify_one()将阻止该线程因更新的counter而进入睡眠，但它也将因后续的wake_one()操作使得第二个线程唤醒。这两个线程将会竞争锁定互斥锁，浪费宝贵的处理器时间。\n', '\n', '这可能听起来就像是一个很少发生的情况，但这实际上可能很容易发生，由于互斥锁如何同步线程。一个将在条件变量上调用notify_one()的线程很可能在此之前锁定并解锁互斥锁，以改变等待线程正在等待的数据。这意味着一旦Condvar::wait()方法解锁了互斥锁，那可能会立即解除一个通知线程的阻塞，该线程正在等待互斥锁。此时，两个线程都在竞争：等待线程要进入睡眠状态，通知线程要锁定和解锁互斥锁并通知条件变量。如果通知线程赢得了这场比赛，等待线程将不会进入睡眠状态，因为计数器已经增加，但是通知线程仍然会调用wake_one()。这正是上述描述的问题情况，它可能不必要地唤醒一个额外的等待线程。\n', '\n', '一个相对直接的解决方案可能是：追踪被允许唤醒的线程数量（也就是从Condvar::wait()返回）。notify_one方法将它增加一，而wait方法尝试在它不为零的情况下将它减一。如果计数器为零，它可以（返回）进入睡眠状态，而不是尝试重新锁定互斥锁并返回。（通知所有线程可以通过增加另一个专门用于notify_all的计数器来完成，该计数器永不递减。）\n', '\n', '这种方法可以工作，但带来了一个新的更微妙的问题：通知可能会唤醒一个还没有调用Condvar::wait()的线程，包括它自己。Condvar::notify_one()的调用会增加应该被唤醒的线程的数量，并使用wake_one()来唤醒一个等待的线程。然后，如果另一个(甚至是相同的)线程在已经等待的线程有机会唤醒之前，调用了Condvar::wait()，新等待的线程可能会发现有一个通知正在等待，于是通过将计数器递减到零立即声明它，立即返回。首次等待的线程将再次进入睡眠，因为另一个线程已经拿走了通知。\n', '\n']['取决于使用情况，这可能完全没问题，或者可能是个大问题，导致某些线程永远无法取得进展。\n', '\n', 'GNU libc的pthread_cond_t实现过去曾受此问题困扰。在多次讨论POSIX规范是否允许这种情况后，这个问题最终在2017年发布的GNU libc 2.25版本中得到解决，该版本包含了全新的条件变量实现。\n', '\n', '在许多使用条件变量的情境中，对于等待者抢走一个先前的通知是完全可以接受的。然而，当实现一个用于通用使用而非特定用途的条件变量时，这种行为可能是无法接受的。\n', '\n', '再次，我们必须得出这个结论，关于我们是否应该使用优化的方法，答案是，“要看情况”。\n', '\n', '有办法在避免此问题的同时，仍然避免虚假唤醒，但这些方法比其它方式要复杂得多。\n', '\n', 'GNU libc的新条件变量解决方案，是将等待者分为两组，只允许第一组消费通知，当第一组没有等待者时交换组。\n', '\n', '这种方法的一个缺点不仅是算法的复杂性，而且还是它显著增加了条件变量类型的大小，因为现在需要跟踪更多信息。\n', '雷声般的群体问题\n', '\n', '另一个可能在使用条件变量时遇到的性能问题，是当使用notify_all()唤醒许多等待相同事情的线程。\n', '\n', '这个问题在于，唤醒后，所有这些线程都将立即试图锁定相同的互斥体。最有可能的是，只有一个线程会成功，其他所有线程都必须再次进入睡眠。这个资源浪费的问题，就是许多线程都争抢同一资源，这被称为雷声般的群体问题。\n', '\n', '有理由认为，Condvar::notify_all()基本上是一个并不值得优化的反模式。条件变量的目的是解锁一个互斥体并在通知时重新锁定，所以可能一次性通知多个线程将不会有什么好处。\n', '\n', '即使如此，如果我们想针对这种情况进行优化，我们可以在支持类似futex的重新排列操作的操作系统上实现，比如Linux上的FUTEX_REQUEUE。(参见第8章的"Futex 操作")\n', '\n', '相比于唤醒许多线程，其中只有一个线程能抢到锁，其余的线程在发现锁已经被拿走后需要立即回去睡觉，我们可以将除一个线程外的所有线程重新排列，使他们的futex等待操作不再等待条件变量的计数器，而改为等待互斥体状态。\n', '\n', '重新排列等待的线程并不会唤醒它。事实上，线程甚至不会知道它已经被重新排列。遗憾的是，这可能会导致一些非常微妙的陷阱。\n', '\n', '例如，记住唤醒后，一个三状态的互斥体必须被锁定到正确的状态（"locked with waiters"）以确保其他等待者不会被忘记。这意味着我们不应再在我们的Condvar::wait()实现中使用普通的互斥体锁定方法，这可能会将互斥体设置为错误的状态。\n', '\n', '一个重新排列的条件变量实现需要存储等待线程使用的互斥体的指针。否则，通知方法不会知道需要将等待线程重新排列到哪个原子变量（互斥体状态）。这就是为什么条件变量通常不允许两个线程等待不同的互斥体。尽管许多条件变量实现并没有使用重新排列，但为将来版本提供这种可能性可能是有用的。\n', '读者-写者锁\n', '\n', '现在是时候实现一个读者-写者锁了！\n', '\n', '回顾一下，与互斥体不同，读者-写者锁支持两种类型的锁定：读锁定和写锁定，有时也被称为共享锁定和排他锁定。写锁定的行为与锁定互斥体的行为完全相同，一次只允许一个锁定，而读锁定允许多个读者同时持有锁定。换句话说，它紧密地匹配了Rust中的独占引用(&mut T)和共享引用(&T)的工作方式，只允许一次激活一个独占引用，或者同时激活任意数量的共享引用。\n', '\n', '对于我们的互斥体，我们只需要追踪它是否被锁定。然而，对于我们的读者-写者锁来说，我们还需要知道当前持有的(读者)锁的数量，以确保在所有读者释放他们的锁之后才进行写锁定。\n', '\n', '让我们从一个RwLock结构开始，它使用一个单独的AtomicU32作为其状态。我们将使用它来表示当前获取的读取锁的数量，这样，零值就表示它是解锁的。要表示写锁定状态，让我们使用u32::MAX的一个特别值。\n', '\n', 'pub struct RwLock<T> {\n', '    /// 读者的数量，或者如果写锁定则为u32::MAX.\n', '    state: AtomicU32,\n', '    value: UnsafeCell<T>,\n', '}\n', '\n', '对于我们的Mutex<T>，我们必须限制它的Sync实现到实现Send的类型T，以确保它不能用于向另一个线程发送，例如，一个Rc。对于我们新的RwLock<T>，我们还需要要求T也实现Sync，因为多个读者将能够一次访问数据：\n', '\n', 'unsafe impl<T> Sync for RwLock<T> where T: Send + Sync {}\n', '\n', '由于我们的RwLock可以以两种不同的方式被锁定，我们将有两个独立的锁定函数，每个函数都有它自己的类型的守卫：\n', '\n', 'impl<T> RwLock<T> {\n', '    pub const fn new(value: T) -> Self {\n', '        Self {\n', '            state: AtomicU32::new(0), // Unlocked.\n', '            value: UnsafeCell::new(value),\n', '        }\n', '    }\n', '\n', '    pub fn read(&self) -> ReadGuard<T> {\n', '        …\n', '    }\n', '\n', '    pub fn write(&self) -> WriteGuard<T> {\n', '        …\n', '    }\n', '}\n', '\n', "pub struct ReadGuard<'a, T> {\n", "    rwlock: &'a RwLock<T>,\n", '}\n', '\n', "pub struct WriteGuard<'a, T> {\n", "    rwlock: &'a RwLock<T>,\n", '}\n', '\n', '写保护应该像一个独占引用(&mut T)那样行为，我们通过为其实现Deref和DerefMut来实现：\n', '\n', "impl<T> Deref for WriteGuard<'_, T> {\n", '    type Target = T;\n', '    fn deref(&self) -> &T {\n', '        unsafe { &*self.rwlock.value.get() }\n', '    }\n', '}\n', '\n', "impl<T> DerefMut for WriteGuard<'_, T> {\n", '    fn deref_mut(&mut self) -> &mut T {\n', '        unsafe { &mut *self.rwlock.value.get() }\n', '    }\n', '}\n', '\n', '然而, 读保护只能实现Deref，不能实现DerefMut，因为它没有对数据的独占访问，使得它的行为就像一个共享引用(&T)：\n', '\n', "impl<T> Deref for ReadGuard<'_, T> {\n", '    type Target = T;\n', '    fn deref(&self) -> &T {\n', '        unsafe { &*self.rwlock.value.get() }\n', '    }\n', '}\n']
['\n', '现在我们已经把所有的样板代码处理掉了，让我们来看看有趣的部分：锁定和解锁。\n', '\n', '要读锁定我们的RwLock，我们必须将状态加一，但只有在它还未被写锁定的时候。我们将用一个比较和交换循环（"比较和交换操作"在第二章中）来做到这一点。如果状态是u32::MAX，意味着RwLock被写锁定，我们将使用一个wait()操作来休眠并稍后重试。\n', '\n', '    pub fn read(&self) -> ReadGuard<T> {\n', '        let mut s = self.state.load(Relaxed);\n', '        loop {\n', '            if s < u32::MAX {\n', '                assert!(s < u32::MAX - 1, "读者过多");\n', '                match self.state.compare_exchange_weak(\n', '                    s, s + 1, Acquire, Relaxed\n', '                ) {\n', '                    Ok(_) => return ReadGuard { rwlock: self },\n', '                    Err(e) => s = e,\n', '                }\n', '            }\n', '            if s == u32::MAX {\n', '                wait(&self.state, u32::MAX);\n', '                s = self.state.load(Relaxed);\n', '            }\n', '        }\n', '    }\n', '\n', '写锁定更容易；我们只需要将状态从零更改为u32::MAX，如果已经锁定则wait():\n', '\n', '    pub fn write(&self) -> WriteGuard<T> {\n', '        while let Err(s) = self.state.compare_exchange(\n', '            0, u32::MAX, Acquire, Relaxed\n', '        ) {\n', '            // Wait while already locked.\n', '            wait(&self.state, s);\n', '        }\n', '        WriteGuard { rwlock: self }\n', '    }\n', '\n', '注意一个锁定的RwLock的确切状态值是多样的，但是wait()操作期待我们给它一个确切的值来比较状态。这就是我们为什么使用比较和交换操作的返回值来进行wait()操作。\n', '\n', '解锁一个读者需要将状态减一。结束解锁RwLock的读者，将状态从一改变为零的读者，负责唤醒一个等待的写者，如果有的话。\n', '\n', '唤醒一个线程就足够了，因为我们知道此时不可能有任何等待的读者。让一个读者等待一个已经读锁定的RwLock是没有任何理由的。\n', '\n', "impl<T> Drop for ReadGuard<'_, T> {\n", '    fn drop(&mut self) {\n', '        if self.rwlock.state.fetch_sub(1, Release) == 1 {\n', '            // 唤醒一个等待的写者，如果有的话。\n', '            wake_one(&self.rwlock.state);\n', '
        }\n', '    }\n', '}\n', '\n', '写者必须将状态重置为零来解锁，然后应唤醒一个等待的写者或所有等待的读者。\n', '\n', '我们不知道读者或写者谁在等待，也没有办法只唤醒一个写者或只唤醒读者。所以，我们将唤醒所有线程：\n', '\n', "impl<T> Drop for WriteGuard<'_, T> {\n", '    fn drop(&mut self) {\n', '        self.rwlock.state.store(0, Release);\n', '        // Wake up all waiting readers and writers.\n', '        wake_all(&self.rwlock.state);\n', '    }\n', '}\n', '\n', '就是这样！我们已经建立了一个非常简单但完全可用的读写锁。\n', '\n', '现在来解决一些问题。\n', '避免繁忙循环的写者\n', '\n', '我们实现的一个问题是写锁定可能导致一个意外的忙循环。\n', '\n', '如果我们有一个RwLock，有很多读者反复锁定和解锁它，锁定状态可能会不断地快速变化。对于我们的write方法，这就造成了锁状态在比较和交换操作与随后的wait()操作之间变化的概率非常大，特别是如果wait()操作直接实现为一个（相对慢的）syscall。这意味着wait()操作通常会立即返回，即使锁从未解开；它只是有比预期更多的读者。\n', '\n', '一个解决方案可以是使用一个不同的AtomicU32让写者等待，并只在我们实际想唤醒一个写者时改变该原子的值。\n', '\n', '让我们试试，通过在我们的RwLock中添加一个新的writer_wake_counter字段：\n', '\n', 'pub struct RwLock<T> {\n', '    /// 读者的数量，或者如果写锁定则是u32::MAX。\n', '    state: AtomicU32,\n', '    /// 递增以唤醒写者。\n', '    writer_wake_counter: AtomicU32, //新的！\n', '    value: UnsafeCell<T>,\n', '}\n', '\n', 'impl<T> RwLock<T> {\n', '    pub const fn new(value: T) -> Self {\n', '        Self {\n', '            state: AtomicU32::new(0),\n', '            writer_wake_counter: AtomicU32::new(0), //新的！\n', '            value: UnsafeCell::new(value),\n', '        }\n', '    }\n', '\n', '    …\n', '}\n', '\n', 'read方法保持不变，但write方法现在需要等待新的原子变量。为了确保我们不会在看到RwLock被读锁定和实际准备睡觉之间错过任何通知，我们将使用我们用于实现我们的条件变量的类似模式：在检查我们是否仍然想睡觉之前检查writer_wake_counter:\n', '\n', '    pub fn write(&self) -> WriteGuard<T> {\n', '        while self.state.compare_exchange(\n']['            0, u32::MAX, Acquire, Relaxed\n', '        ).is_err() {\n', '            let w = self.writer_wake_counter.load(Acquire);\n', '            if self.state.load(Relaxed) != 0 {\n', '                // 如果RwLock仍然被锁定，但只有在此之后我们没有收到唤醒信号时，才等待\n', '                wait(&self.writer_wake_counter, w);\n', '            }\n', '        }\n', '        WriteGuard { rwlock: self }\n', '    }\n', '\n', 'writer_wake_counter的获取-加载操作将与解锁状态之后立即执行的发布-增量操作形成一个发生-之前的关系，然后再唤醒等待的写入器：\n', '\n', "impl<T> Drop for ReadGuard<'_, T> {\n", '    fn drop(&mut self) {\n', '        if self.rwlock.state.fetch_sub(1, Release) == 1 {\n', '            self.rwlock.writer_wake_counter.fetch_add(1, Release); // 新的！\n', '            wake_one(&self.rwlock.writer_wake_counter); // 改变！\n', '        }\n', '    }\n', '}\n', '\n', '发生-之前的关系确保了在write方法不能观察到writer_wake_counter增加的值，同时还看到了状态值仍未减少。否则，写锁定的线程可能会得出RwLock仍然被锁定的结论，但已经错过了唤醒通话。\n', '\n', '和以前一样，写解锁应该唤醒一个等待的写入器或所有等待的读取器。由于我们仍然不知道是否有等待的写入器或读取器，我们必须同时唤醒一个等待的写入器（通过wake_one）和所有等待的读取器（使用wake_all）：\n', '\n', "impl<T> Drop for WriteGuard<'_, T> {\n", '    fn drop(&mut self) {\n', '        self.rwlock.state.store(0, Release);\n', '        self.rwlock.writer_wake_counter.fetch_add(1, Release); // 新的！\n', '        wake_one(&self.rwlock.writer_wake_counter); // 新的！\n', '        wake_all(&self.rwlock.state);\n', '    }\n', '}\n', '\n', '在某些操作系统中，唤醒操作背后的操作返回的是它唤醒的线程数。尽管有可能因误唤醒的线程而比实际唤醒的线程数少，但其返回值仍可作为优化的有用信息。\n', '\n', '例如，在上述drop的实现中，如果wake_one()操作表明它实际唤醒了一个线程，我们可以跳过wake_all()的调用。\n', '避免写者饥饿\n', '\n', 'RwLock的一个常见用例是有许多频繁的读者，但很少，通常只有一个，不频繁的写者的情况。例如，一个线程可能负责读取一些传感器输入或周期性下载其他许多线程需要使用的一些新数据。\n', '\n', '在这种情况下，我们很快就会遇到一个叫做写者饥饿的问题：写者永远没有机会锁定RwLock，因为总是有读者在那里，让RwLock读锁定。\n', '\n', '解决这个问题的一个方法是当有一个写入器等待时，阻止任何新的读取器获取锁，即使RwLock仍然是读锁定的。这样，所有新的读者都将不得不等到写入器轮到它为止，确保读者能够访问写入器想要分享的最新数据。\n', '\n', '我们来实现这个。\n', '\n', '为此，我们需要跟踪是否有任何等待的写入器。为了在状态变量中为这个信息预留空位，我们可以将读者数量乘以2，并在有写入器等待时加1。这意味着状态为6或7都代表着有三个活跃的读锁的情况：6 代表没有等待的写作者，7 代表有一个等待的写作者。\n', '\n', '我们保持u32::MAX，这是一个奇数，作为写锁定状态，那么读者将不得不在状态为奇数时等待，但是自由地在状态为偶数时通过增加2来获得读锁。\n', '\n', 'pub struct RwLock<T> {\n', "    /// 读锁的数量乘以二，加上如果有一个写者在等待的话就加一。\n", '    /// u32::MAX如果写锁定。\n', '    ///\n', '    /// 这意味着读者可能在状态为偶数时获取锁，\n', '    /// 但需要在奇数时阻塞。\n', '    state: AtomicU32,\n', '    /// 增加来唤醒写入器。\n', '    writer_wake_counter: AtomicU32,\n', '    value: UnsafeCell<T>,\n', '}\n', '\n', '我们必须改变我们的读方法中的两个if语句，不再将状态与u32::MAX进行比较，而是检查状态是偶数还是奇数。我们也需要确保我们通过增加两个而不是一个来锁定。\n', '\n', '    pub fn read(&self) -> ReadGuard<T> {\n', '        let mut s = self.state.load(Relaxed);\n', '        loop {\n', '            if s % 2 == 0 { // Even.\n', '                assert!(s < u32::MAX - 2, "读者过多");\n', '                match self.state.compare_exchange_weak(\n', '                    s, s + 2, Acquire, Relaxed\n', '                ) {\n', '                    Ok(_) => return ReadGuard { rwlock: self },\n', '                    Err(e) => s = e,\n', '                }\n', '            }\n', '            if s % 2 == 1 { // Odd.\n', '                wait(&self.state, s);\n', '                s = self.state.load(Relaxed);\n', '            }\n', '        }\n', '    }\n', '\n', '我们的写方法必须经历更大的更改。我们将使用一个比较和交换的循环，就像我们上面的读方法一样。如果状态是0或1，这意味着RwLock是解锁的，我们将尝试将状态更改为u32::MAX以对其进行写锁定。否则，我们必须等待。在这样做之前，我们需要确保状态是奇数，以阻止新的读者获取锁。在保证状态是奇数的前提下，我们等待writer_wake_counter变量，同时确保锁在此期间没有被解锁。\n', '\n', '在代码中，这看起来像这样：\n', '\n', '    pub fn write(&self) -> WriteGuard<T> {\n', '        let mut s = self.state.load(Relaxed);\n', '        loop {\n', '            // 尝试锁定，如果未被锁定。\n', '            if s <= 1 {\n', '                match self.state.compare_exchange(\n', '                    s, u32::MAX, Acquire, Relaxed\n', '                ) {\n', '                    Ok(_) => return WriteGuard { rwlock: self },\n', '                    Err(e) => { s = e; continue; }\n']['                }\n', '            }\n', '            // 通过确保状态为奇数来阻止新的读取。\n', '            如果 s % 2 == 0 {\n', '                匹配 self.state.compare_exchange(\n', '                    s, s + 1, Relaxed, Relaxed\n', '                ) {\n', '                    Ok(_) => {}\n', '                    Err(e) => { s = e; 继续; }\n', '                }\n', '            }\n', "            // 如果仍然被锁定，等待\n", '            let w = self.writer_wake_counter.load(Acquire);\n', '            s = self.state.load(Relaxed);\n', '            如果 s >= 2 {\n', '                等待(&self.writer_wake_counter, w);\n', '                s = self.state.load(Relaxed);\n', '            }\n', '        }\n', '    }\n', '\n', '因为我们现在追踪是否有等待的写者，所以读解锁现在可以在不必要的情况下跳过 wake_one() 调用：\n', '\n', "impl<T> Drop for ReadGuard<'_, T> {\n", '    fn drop(&mut self) {\n', '        // 将状态减少 2 来删除一个读锁。\n', '        if self.rwlock.state.fetch_sub(2, Release) == 3 {\n', '            // 如果我们从 3 减少到 1，那就意味着\n', '            // RwLock 现在解锁了 _并且_ 有\n', '            // 一个等待的写者，我们可以唤醒他。\n', '            self.rwlock.writer_wake_counter.fetch_add(1, Release);\n', '            wake_one(&self.rwlock.writer_wake_counter);\n', '        }\n', '    }\n', '}\n', '\n', '在写锁定（一个 u32::MAX 的状态）时，我们不追踪任何关于是否有线程在等待的信息。所以，我们没有新的信息可以用于写解锁，这将保持不变：\n', '\n', "impl<T> Drop for WriteGuard<'_, T> {\n", '    fn drop(&mut self) {\n', '        self.rwlock.state.store(0, Release);\n', '        self.rwlock.writer_wake_counter.fetch_add(1, Release);\n', '        wake_one(&self.rwlock.writer_wake_counter);\n', '        wake_all(&self.rwlock.state);\n', '    }\n', '}\n', '\n', '对于一个针对"频繁读取和不频繁写入"用例进行优化的读写锁，这是完全可以接受的，因为写锁（以及解锁）发生的不频繁。\n', '\n', '对于一个更通用的读写锁，优化进一步是肯定值得的，以获得接近高效3状态互斥锁的写锁定和解锁的性能。这就留给读者作为一个有趣的练习。\n', '总结\n', '\n', '    atomic-wait 包提供了基本的 futex-like 功能，适用于所有主要操作系统的（最新版本）。\n', '\n', '    一个最小的互斥锁实现只需要两个状态，就像我们在第4章的 SpinLock。\n', '\n', '    一个更高效的互斥锁可以追踪是否有等待的线程，以避免不必要的唤醒操作。\n', '\n', '    在进入睡眠之前旋转在某些情况下可能是有益的，但这很大程度上取决于情况，操作系统和硬件。\n', '\n', '    一个最小的条件变量只需要一个通知计数器，这个条件变量::等待将必须在解锁互斥体前后进行检查。\n', '\n', '    一个条件变量可以追踪等待的线程数量以避免不必要的唤醒操作。\n', '\n', '    避免从条件变量::等待假醒可以很棘手，需要额外的记录。\n', '\n', '    一个最小的读写锁只需要一个原子计数器作为其状态。\n', '\n', '    一个额外的原子变量可以被用于独立从读取者唤醒写入者。\n', '\n', '    为了避免写者的饿死，需要额外的状态来优先等待的写者超过新的读取者。\n']