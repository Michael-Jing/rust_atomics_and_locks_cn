['第7章. 了解处理器\n', '\n', '虽然第2章和第3章的理论就足够我们编写正确的并发代码，但是进一步了解处理器级别的实际操作可以提供更多的帮助。在这一章，我们将探究原子操作所编译的机器指令，不同处理器架构的差异，为什么存在 compare_exchange 的弱版本，什么是最底层单个指令的内存排序，以及缓存是如何涉及到所有这些的。\n', '\n', '本章的目标并不是理解关于每一种处理器架构的所有相关细节。这需要填满许多书架的书，很多还可能尚未编写或未公开发表。相反，本章的目标是开发对处理器级别的原子操作的一般性理解，以便在实施和优化涉及原子操作的代码时做出更明智的决定。当然，也是为了满足我们对幕后发生了什么的好奇——暂时离开所有抽象的理论。\n', '\n', '为了具体化，我们将重点关注两种特定的处理器架构：\n', '\n', 'x86-64：\n', '\n', '    由 Intel 和 AMD 处理器实现的 x86 架构的64位版本，被用于大多数的笔记本电脑，台式机，服务器和一些游戏机。虽然最初的16位 x86 架构及其非常流行的 32 位扩展是由 Intel 开发的，但我们现在称之为 x86-64 的64位版本最初是由 AMD 开发的扩展，常被称为 AMD64。Intel 也开发了自己的64位架构，IA-64，但最终采用了 AMD 更受欢迎的 x86 扩展（在名字上被称为 IA-32e，EM64T，以及后来的 Intel 64）。\n', 'ARM64：\n', '\n', '    ARM 架构的 64 位版本，几乎所有现代移动设备，高性能嵌入式系统以及最近的笔记本电脑和台式电脑都在使用。也被称为 AArch64 并作为 ARMv8 的一部分引入。早期的 ARM（32位）版本，在许多方面相似，用于更多种类的应用。很多受欢迎的微控制器，在从汽车到电子 COVID 测试的所有类型的嵌入式系统中都以 ARMv6 和 ARMv7为基础。\n', '\n', '这两种架构在许多方面都不同。最重要的是，它们对原子操作的处理方式不同。理解在这两个系统中原子操作是如何工作的可以让我们更全面地理解其他许多架构。\n', '处理器指令\n', '\n', '我们可以通过仔细查看编译器的输出，即处理器将执行的确切指令，大致了解处理器级别如何工作。\n', '简要介绍汇编\n', '\n', '当编译由 Rust 或 C 这类编译语言编写的软件时，你的代码会被翻译成可以由最终运行你的程序的处理器执行的机器指令。这些指令与你编译程序的处理器架构高度相关。\n', '\n', '这些指令，也被称为机器码，以二进制形式编码，对于我们人类来说，这是相当难以阅读的。汇编语言是这些指令的人类可读表示。每个指令由一行文本表示，通常由一个单词或首字母缩写开头以标识指令，后面跟着它的参数或操作数。汇编器将文本表示转换为二进制表示，反汇编器则执行相反的操作。\n', '\n', '从像 Rust 这样的语言编译之后，原始源代码的大部分结构都已失去。根据优化级别，函数和函数调用可能仍然可以识别。然而，像 struct 或 enum 这样的类型已经被简化为字节和地址，循环和条件语句已经被简化为带有基本跳转或分支指令的平面结构。\n', '\n', '以下是一个示例，展示了一部分程序的汇编片段可能是什么样子，使用了一种虚构的架构：\n', '\n', 'ldr x, 1234 // 加载内存地址1234到x\n', 'li y, 0     // 将 y 设为0\n', 'inc x       // x 自加 1 \n', 'add y, x    // 将 x 添加到 y\n', 'mul x, 3    // 让 x 乘以 3 \n', 'cmp y, 10   // 与 10 比较 y \n', 'jne -5      // 如果不相等则跳转回五个指令\n', 'str 1234, x // 把 x 存到内存地址1234\n', '\n', '在此示例中，x和y是寄存器的名称。寄存器是处理器的一部分，不是主要的内存部分，并且通常可以保存一个整数或内存地址。在64位架构上，它们一般都是64位的。每种架构的寄存器数量各不相同，但通常非常有限。寄存器基本上用作计算中的临时便签，保留中间结果，然后再将数据存回内存。\n', '\n', '常量是引用特定内存地址，例如上面的示例中的 1234 和 -5，通常被替换为更易于人类阅读的标签。当汇编器将汇编转换为二进制机器代码时，将自动用实际地址替换它们。\n', '\n', '使用标签，前面的例子可能会这样写：\n', '\n', '       ldr x, SOME_VAR\n', '       li y, 0\n', 'my_loop: inc x\n', '       add y, x\n', '       mul x, 3\n', '       cmp y, 10\n', '       jne my_loop\n', '       str SOME_VAR, x\n', '\n', '由于标签名称只是汇编的一部分，而不是二进制机器代码的一部分，反汇编器不会知道原来使用的是什么标签，所以大概率只会使用毫无意义的生成名字，如 label1 和 var2。\n', '\n', '关于所有不同架构的汇编课程，完全超出了本书的范围，但不是阅读本章的先决条件。非常一般的理解就足够理解这些示例，因为我们只是读汇编，而不是编写它。每个示例中的相关指令将解释得足够详细，即使没有汇编的先前经验，你也可以跟随其中。\n', '\n', '要查看 Rust 编译器产生的精确的机器码，我们有几个选择。我们可以像平常一样编译代码，然后使用反汇编器（如 objdump）将生成的二进制文件还原成汇编。使用编译器作为编译过程的一部分产生的调试信息，反汇编器可以生成对应于 Rust 源代码的原始函数名的标签。这种方法的缺点是你需要一个支持所编译的特定处理器架构的反汇编器。尽管 Rust 编译器支持许多架构，但许多反汇编器只支持它们编译的那种架构。\n', '\n', '更直接的选择是使用 --emit=asm 标志向 rustc 请求生成汇编而不是二进制文件。这种方法的缺点是生成的输出包含许多无关的行，包括我们不需要的汇编器和调试工具的信息。\n', '\n', '有一些很好的工具，如 cargo-show-asm，可以与 cargo 集成并自动化使用正确标志编译 crate 的流程，找到你感兴趣的函数的相关汇编，并高亮显示包含实际指令的相关行。\n', '\n', '对于相对较小的代码片段，最简单和最推荐的方式是使用像 Matt Godbolt 的优秀 Compiler Explorer 这样的网络服务。这个网站允许你用许多语言（包括 Rust）编写代码，并直接看到使用所选编译器版本的对应编译的汇编。它甚至用颜色标出哪些 Rust 行对应哪些汇编行，只要优化后仍存在这种对应。\n', '\n', '由于我们想看不同架构的汇编，我们需要为 Rust 编译器指定一个确切的目标来编译。我们会使用 x86_64-unknown-linux-musl 作为 x86-64，对于 ARM64 我们会使用 aarch64-unknown-linux-musl。它们已经直接在 Compiler Explorer 中支持。如果你在本地编译，例如使用 cargo-show-asm 或上面提到的其他方法，你需要确保已安装这些目标的 Rust 标准库，通常是使用 rustup target add。\n', '\n', '在所有情况下，选编译目标是使用 --target 编译器标志。例如，--target=aarch64-unknown-linux-musl。如果你没有指定任何目标，它会自动选择你当前所在的平台。（或者，在 Compiler Explorer 的情况下，选择托管它的平台，当前是 x86_64-unknown-linux-gnu。）\n', '\n', '此外，建议启用 -O 标志以启用优化（或使用 Cargo 时 --release），这将启用优化并禁用溢出检查，这可以显著减少我们在此观察的小函数生成的汇编数量。\n', '\n', '为了试验，我们看看以下函数的 x86-64 和 ARM64 的汇编：\n', '\n', 'pub fn add_ten(num: &mut i32) {\n', '    *num += 10;\n', '}\n', '\n', '使用 -O --target=aarch64-unknown-linux-musl 作为编译器标志，任何上述的方法我们都会得到类似于 ARM64 的下面的汇编输出：\n', '\n', 'add_ten:\n', '    ldr w8, [x0]\n', '    add w8, w8, #10\n', '    str w8, [x0]\n', '    ret\n', '\n', '寄存器 x0 包含我们的函数参数 num，增加十个的 i32的地址。首先，ldr 指令将该内存地址的 32 位值加载到 w8 寄存器中。然后，add 指令将十加到 w8 并将结果存回 w8。之后，str 指令将 w8 寄存器存回到同一内存地址。最后，ret 指令标识函数的结束，并使处理器跳回并继续执行调用 add_ten 的函数。\n', '\n', '如果我们为 x86-64-unknown-linux-musl 编译同样的代码，我们会得到类似这样的：\n', '\n', 'add_ten:\n', '    add dword ptr [rdi], 10\n', '    ret\n', '\n', '这次，一个名为 rdi 的寄存器用于 num 参数。更有趣的是，对 x86-64，一个 add 指令就可以做到 ARM64 需要三条指令所做的事情：加载，递增和存储值。\n', '\n', '这种情况通常出现在复杂指令集计算机 (CISC) 架构，比如 x86，上面。这样的架构上的指令通常有许多变体，比如操作寄存器或直接操作特定大小的内存。（汇编中的 dword 指定了 32 位操作。）\n', '\n', '相反，一个精简指令集计算机 (RISC) 架构，如 ARM，通常有一个较为简单的指令集，变体很少。大多数指令只能操作寄存器，加载和存储到内存需要单独的指令。这允许构建一个更简单的处理器，可能导致成本降低或有时性能更高。\n', '\n', '这种差异对于原子获取和修改指令特别相关，我们会很快看到。\n']['\n', '虽然编译器通常很聪明，但它们并不总是生成最优的汇编，尤其是当涉及到原子操作时。如果你正在进行实验，发现某些情况下，汇编中似乎不必要的复杂性让你感到困惑，那通常只意味着未来版本的编译器有更多的优化机会。\n', '加载和存储\n', '\n', '在我们深入探讨更高级的内容之前，先让我们看看用于最基本原子操作的指令：加载和存储。\n', '\n', '一个常规的非原子存储通过一个&mut i32只需要在x86-64和ARM64上单独执行一条指令，如下所示：\n', 'Rust源代码\t编译后的x86-64\t编译后的ARM64\n', '\n', 'pub fn a(x: &mut i32) {\n', '    *x = 0;\n', '}\n', '\n', '\t\n', '\n', 'a：\n', '    mov dword ptr [rdi], 0\n', '    ret\n', '\n', '\t\n', '\n', 'a：\n', '    str wzr, [x0]\n', '    ret\n', '\n', '在x86-64上，用于将数据从一个地方复制（"移动"）到另一个地方的非常通用的mov指令被使用；在这种情况下，从零常数到内存。在ARM64上，使用str（存储寄存器）指令将32位寄存器存储到内存中。在这种情况下，使用了特殊的wzr寄存器，它总是包含零。\n', '\n', '如果我们改变代码，而是使用一个松散的原子存储到AtomicI32，我们得到：\n', 'Rust源代码\t编译后的x86-64\t编译后的ARM64\n', '\n', 'pub fn a(x: &AtomicI32) {\n', '    x.store(0, Relaxed);\n', '}\n', '\n', '\t\n', '\n', 'a：\n', '    mov dword ptr [rdi], 0\n', '    ret\n', '\n', '\t\n', '\n', 'a：\n', '    str wzr, [x0]\n', '    ret\n', '\n', '或许有些令人惊讶，汇编与非原子版本完全相同。事实证明，mov和str指令已经是原子的。它们要么发生，要么完全不发生。显然，&mut i32和&AtomicI32之间的任何区别在这里只与编译器的检查和优化有关，但对处理器来说是无意义的——至少在这两种架构上对松散存储操作来说是这样。\n', '\n', '查看松散加载操作时，同样的事情会发生：\n', 'Rust源代码\t编译后的x86-64\t编译后的ARM64\n', '\n', 'pub fn a(x: &i32) -> i32 {\n', '    *x\n', '}\n', '\n', '\t\n', '\n', 'a：\n', '    mov eax, dword ptr [rdi]\n', '    ret\n', '\n', '\t\n', '\n', 'a：\n', '    ldr w0, [x0]\n', '    ret\n', '\n', 'pub fn a(x: &AtomicI32) -> i32 {\n', '    x.load(Relaxed)\n', '}\n', '\n', '\t\n', '\n', 'a：\n', '    mov eax, dword ptr [rdi]\n', '    ret\n', '\n', '\t\n', '\n', 'a：\n', '    ldr w0, [x0]\n', '    ret\n', '\n', '在x86-64上，mov指令再次被使用，这次是从内存中复制到32位eax寄存器。在ARM64上，使用ldr（加载寄存器）指令将值从内存加载到w0寄存器。\n', '\n', '32位eax和w0寄存器用于返回函数的32位返回值。（对于64位值，使用64位rax和x0寄存器。）\n', '\n', '尽管处理器显然不区分原子和非原子的存储和加载，我们在Rust代码中不能安全地忽略这种差别。如果我们使用&mut i32，Rust编译器可能会假设没有其他线程可以同时访问同一个i32，可能决定以这样一种方式转换或优化代码，即存储操作不再对应于单个存储指令。例如，非原子的32位加载或存储可以通过两个单独的16位指令进行，虽然这有点不寻常。\n', '读-修改-写操作\n', '\n', '对于读-修改-写操作如加法，情况就变得更有趣。如本章前面所讨论的，非原子读-修改-写操作在像ARM64这样的RISC架构上通常会编译成三个单独的指令（读取，修改和写入），但在像x86-64这样的CISC架构上，通常可以用一条指令完成。这个短例子显示了这一点：\n', 'Rust源代码\t编译后的x86-64\t编译后的ARM64\n', '\n', 'pub fn a(x: &mut i32) {\n', '    *x += 10;\n', '}\n', '\n', '\t\n', '\n', 'a：\n']['    在dword ptr [rdi]处加10\n', '  ret\n', '\n', '\t\n', '\n', 'a:\n', '    ldr w8, [x0]\n', '    在w8处加10\n', '    str w8, [x0]\n', '   ret\n', '\n', '在我们看相应的原子操作之前，我们可以合理地假设这次我们会看到非原子和原子版本之间的差异。这里的ARM64版本显然不是原子的，因为加载和存储是分步骤进行的。\n', '\n', '尽管从汇编本身来看并不直接明显，但x86-64版本并非原子的。add指令将由处理器在后台分解成几个微指令，其中包括用于加载值和存储结果的单独步骤。在单核计算机上，这将无关紧要，因为处理器核心在指令之间通常只在线程之间切换。然而，当多个核心并行执行指令时，我们不能再假设所有的指令都是原子性的，没有考虑执行单个指令所涉及的多个步骤。\n', 'x86锁定前缀\n', '\n', '为了支持多核系统，英特尔引入了一个称为锁的指令前缀。它被用作一种修饰符，应用于像add这样的指令，使其操作具有原子性。\n', '\n', '锁前缀最初会使处理器在指令执行期间暂时阻止所有其他核心访问内存。虽然这是一种简单有效的方式，使其他核心看起来像是原子的，但是对于每一个原子操作都停止世界来说，这可能相当低效。较新的处理器对锁定前缀有更先进的实现方式，这不会阻止其他核心操作无关的内存，而且在等待某块内存可用的同时还可以让核心做些有用的事情。\n', '\n', '锁前缀只能用于一些指令操作，包括加、减、取和、非、或和异或，这些都是非常有用的并能够以原子方式进行的操作。xchg(交换)指令，对应于原子交换操作，有一个隐式的锁前缀，无论是否有锁前缀，它的行为都类似于lock xchg。\n', '\n', '让我们通过改变我们最后一个例子来操作一个AtomicI32，看看lock add在实际中的效果：\n', 'Rust源代码\t编译的x86-64\n', '\n', 'pub fn a(x: &AtomicI32) {\n', '    x.fetch_add(10, Relaxed);\n', '}\n', '\n', '\t\n', '\n', 'a:\n', '    对dword ptr [rdi]上锁并添加10\n', '    ret\n', '\n', '正如预期的，与非原子版本的唯一区别是锁前缀。\n', '\n', '在上述例子中，我们忽略了fetch_add的返回值，即操作前的x的值。然而，如果我们使用那个值，add指令就不再足够了。add指令能向后续指令提供一些有用的信息，比如更新后的值是否为零或负值，但它不能提供完整的（原始或更新的）值。取而代之的是另一个指令，可以使用的是xadd（“交换和添加”），它将最初加载的值放入一个寄存器。\n'. '我们可以看到它的动作，我们对代码进行小修改，返回fetch_add返回的值：\n', 'Rust源代码\t编译的x86-64\n', '\n', 'pub fn a(x: &AtomicI32) -> i32 {\n', '    x.fetch_add(10, Relaxed)\n', '}\n', '\n', '\t\n', '\n', 'a:\n', '    mov eax, 10\n', '    锁定xadd dword ptr [rdi], eax\n', '    ret\n', '\n', '现在不再使用常量10，而是使用包含值10的寄存器。这个xadd指令会重复使用这个寄存器来存储旧的值。\n', '\n', '不幸的是，除了xadd和xchg，这些允许锁定前缀的指令，如sub、amp、or等都没有这样的变体。例如，没有xsub指令。对于减法，这就没有问题了，因为xadd可以用负值。然而，对于和和或，没有这样的替代品。\n', '\n', '对于只影响单个位的and、or和xor操作，如fetch_or(1)或fetch_and(!1)，可以使用bts(测试和设置位)、btr(测试和重置位)和btc (测试和取反位)指令。这些指令也允许锁定前缀，只改变一个单独的位，并使该位的前一个值可用于后面的指令，比如一个有条件的跳跃。\n','\n', '当这些操作影响超过一个位时，它们不能由单个的x86-64指令表示。同样地，fetch_max和fetch_min操作也没有对应的x86-64指令。对于这些操作，我们需要的策略不同于简单的锁定前缀。\n', 'x86比较和交换指令\n', '\n', '在第二章的"比较和交换操作"中，我们看到了任何原子的fetch-and-modify操作都能作为比较和交换循环被实现。这就是编译器将用于不能由单个x86-64指令表示的操作，因为该架构的确包含了一个可以附加锁定前缀的cmpxchg（比较和交换）指令。\n', '\n', '我们可以看到它的动作，我们将最后一个例子从fetch_add变为fetch_or：\n', 'Rust源代码\t编译的x86-64\n', '\n', 'pub fn a(x: &AtomicI32) -> i32 {\n', '    x.fetch_or(10, Relaxed)\n', '}\n', '\n', '\t\n', '\n', 'a:\n', '    mov eax, dword ptr [rdi]\n', '.L1:\n', '    mov ecx, eax\n', '    或 ecx, 10\n', '    锁定cmpxchg dword ptr [rdi], ecx\n', '    不等则跳到.L1\n', '    ret\n', '\n', '第一mov指令将原子变量的值加载到eax寄存器。后面的mov和or指令将该值复制到ecx并应用二进制或操作，使得eax包含了旧值，ecx则包含新值。随后的cmpxchg指令的行为与Rust中的compare_exchange方法完全相同。它的第一个参数是要操作的内存地址（原子变量），第二个参数（ecx）是新的值，预期值是从eax隐式地取出，返回值也是隐式地存储在eax。它也设置了一个状态标志，后续指令可以根据操作是否成功使用它做出条件分支。在本例中，jne(如果不等于则跳转)指令被用来在失败时返回.L1标签以再尝试。\n', '\n', '下面是Rust中的等价比较和交换循环看起来的样子，就像我们在第二章的"比较和交换操作"中看到的那样：\n', '\n', 'pub fn a(x: &AtomicI32) -> i32 {\n', '    let mut current = x.load(Relaxed);\n', '    loop {\n', '        let new = current | 10;\n', '        match x.compare_exchange(current, new, Relaxed, Relaxed) {\n', '            Ok(v) => return v,\n', '            Err(v) => current = v,\n', '        }\n', '    }\n', '}\n', '\n', '这段代码与fetch_or版本有着完全一样的汇编版本。这表明，至少在x86-64上，这两者实际上是完全等同的。\n', '\n', '在x86-64上， compare_exchange和 compare_exchange_weak之间没有任何的差别。这两个都会用锁定的cmpxchg指令编译。\n'
['加载链接和存储条件指令\n', '\n', '在RISC架构上最接近比较和交换循环的东西是一个加载链接/存储条件（LL/SC）循环。它包括两个配对的特殊指令：一个加载链接指令，其行为大多像一个常规的加载指令；一个存储条件指令，其行为大多像一个常规的存储指令。这两个指令被用来配对，它们的目标都是同一个内存地址。与常规的加载和存储指令的关键区别在于这个存储是有条件的：如果任何其他线程自从加载链接指令以来覆盖了那个内存，它就会拒绝向内存中存储。\n', '\n', '这两个指令让我们能够从内存中加载一个值，改变它，然后仅在没有人覆盖我们加载的那个值时将新的值存回。如果这失败，我们就可以简单地重试。一旦成功，我们就可以安全地假装整个操作是原子的，因为它没有被打断。\n', '\n', '使这些指令可行和高效实现的关键有二：（1）只有一个内存地址（每个核）可以一次被跟踪，（2）存储条件允许有假的阴性，意味着它可能会失败即使没有任何变化影响了特定的内存块。\n', '\n', '这使得它有可能在跟踪记忆的变化时不那么精确，可能需要通过一个LL/SC循环额外的几个周期。内存的访问可能不是按字节跟踪，而是以64字节的块，或者以千字节，或者甚至整个内存作为一个整体。低精度的内存跟踪会导致通过LL/SC循环的更多不必要的周期，显著降低性能，但也降低了实现的复杂度。\n', '\n', '将事情推向极致，一个基础的，假设的单核系统可以使用一种不跟踪内存写入的策略。相反，它可以跟踪中断或上下文切换，这些事件可以导致处理器切换到另一条线程。如果在一个没有任何并行性的系统中，没有这样的事件发生，它就可以安全地假设没有其他线程可能触及到内存。如果有这样的事件发生，它就可以假设最坏的情况，拒绝这个存储，并希望在循环的下一次迭代中有更好的运气。\n', 'ARM加载独占和存储独占\n', '\n', '在ARM64上，或者至少在ARMv8的第一版中，没有任何原子性的获取并修改或者比较并交换操作可以被单一的指令表示。忠实于其RISC的本质，加载和存储的步骤与计算和比较是分开的。\n', '\n', 'ARM64的加载链接和存储条件指令被称为ldxr（加载独占寄存器）和stxr（存储独占寄存器）。此外，clrex（清除独占）指令可以被用做一个stxr的替代品，用于停止跟踪写入到内存的情况，而不存储任何东西。\n', '\n', '为了看到他们的作用，让我们看看我们在ARM64上进行原子性加法时会发生什么：
 Rust源\t编译ARM64\n', '\n', 'pub fn a(x: &AtomicI32) {\n', '    x.fetch_add(10, Relaxed);\n', '}\n', '\n', '\t\n', '\n', 'a:\n', '.L1:\n', '    ldxr w8, [x0]\n', '    add w9, w8, #10\n', '    stxr w10, w9, [x0]\n', '    cbnz w10, .L1\n', '    ret\n', '\n', '我们得到的东西看起来很像我们之前得到的非原子版本(在"读-修改-写操作"中)：一个加载指令，一个添加指令，和一个存储指令。加载和存储指令已经被替换为他们的"独占" LL/SC版本，出现了一个新的cbnz（比较和分支非零）指令。如果stxr指令成功，那么它在w10中存储一个0，如果它不成功，那么它存储一个1。cbnz指令使用这个来重新开始整个操作，如果它失败了。\n', '\n', '注意，与x86-64上的锁定添加不同，我们不需要做任何特殊的事情来检索旧的值。在上面的例子中，操作成功后，旧值仍然在寄存器w8中可用，因此不需要像xadd那样的专门指令。\n', '\n', '这个LL/SC模式相当灵活:它不仅适用于一定范围的操作，如添加和或，还适用于几乎所有的操作。我们可以同样轻松地通过在ldxr和stxr指令之间放置相应的指令来实现原子性的fetch_divide或fetch_shift_left。然而，如果它们之间的指令过多，打断的机会就会增加，导致额外的循环。通常，编译器会尝试使LL/SC模式中的指令数量尽可能小，以避免LL/SC循环，这可能很少甚至从未成功，因此可能会永远旋转。','ARMv8.1原子指令\n', '\n', 'ARM64的一个后期版本，是ARMv8.1的一部分，也包括了一些新的CISC风格的常用原子操作指令。例如，新的ldadd（加载和添加）指令等同于一个原子的fetch_add操作，而不需要一个LL/SC循环。它甚至包括了一些像fetch_max这样的操作指令，这在x86-64上并不存在。\n', '\n', '它还包括了一个cas（比较和交换）指令，它对应于compare_exchange。当这个指令被使用时，compare_exchange和compare_exchange_weak之间就没有任何差别，就像在x86-64上一样。\n', '\n', '虽然LL/SC模式非常灵活并且很好地适配了通用的RISC模式，但这些新的指令可以更有效，因为它们可以更容易地通过专门的硬件进行优化。\n', '在ARM上的比较和交换\n', '\n', 'compare_exchange操作能够通过使用一个条件分支指令，只有在比较失败的时候跳过存储指令，很好地映射到这个LL/SC模式上。让我们看看生成的汇编：\n', 'Rust源\t编译ARM64\n', '\n', 'pub fn a(x: &AtomicI32) {\n', '    x.compare_exchange_weak(5, 6, Relaxed, Relaxed);\n', '}\n', '\n', '\t\n', '\n', 'a:\n', '    ldxr w8, [x0]\n', '    cmp w8, #5\n', '    b.ne .L1\n', '    mov w8, #6\n', '    stxr w9, w8, [x0]\n', '    ret\n', '.L1:\n', '    clrex\n', '    ret\n', '\n', '注意，一个compare_exchange_weak操作通常在比较失败时在一个循环中使用。然而，对于这个例子，我们只调用一次，忽略其返回值，这显示了我们理解汇编没有分心的事情。\n', '\n', 'ldxr指令加载值，然后立即使用cmp（比较）指令将其与预期值5进行比较。如果值不符合期望，b.ne（分支不等）指令会跳转到.L1标签，此时clrex指令被用来中止LL/SC模式。如果值是五，流程会通过mov和stxr指令继续，只有在没有东西覆盖五的同时才在内存中存储新的六值。\n', '\n', '请记住，stxr被允许有假阴性；即使五并未被覆盖，这里也可能失败。这是可以的，因为我们正在使用compare_exchange_weak，它也被允许有假阴性。事实上，这就是为什么compare_exchange存在的一个弱版本的原因。\n', '\n', '如果我们用compare_exchange替换compare_exchange_weak，我们得到几乎完全相同的汇编，除了一个额外的分支来重新开始操作，如果它失败了：\n', 'Rust源\t编译ARM64\n', '\n', 'pub fn a(x: &AtomicI32) {\n', '    x.compare_exchange(5, 6, Relaxed, Relaxed);\n', '}\n', '\n', '\t\n', '\n', 'a:\n', '    mov w8, #6\n', '.L1:\n', '    ldxr w9, [x0]\n', '    cmp w9, #5\n', '    b.ne .L2\n', '    stxr w9, w8, [x0]\n', '    cbnz w9, .L1\n', '    ret\n', '.L2:\n', '    clrex\n', '    ret\n', '\n', '如预期，现在有一个额外的cbnz（比较和非零分支）指令，用于在失败时重新启动LL/SC循环。另外，mov指令已经被移出循环，以使循环尽可能短。\n', '比较和交换循环的优化\n', '\n', '正如我们在"x86比较和交换指令"中看到的，一个fetch_or操作和等效的compare_exchange循环编译到x86-64的完全相同的指令。人们可能希望在ARM上也会发生同样的事情，至少是跟compare_exchange_weak一样，因为加载和弱比较和交换操作可以直接映射到LL/SC指令。\n']['\n', '不幸的是，目前（截至Rust 1.66.0版）的情况并非如此。\n', '\n', '尽管编译器一直在不断改进，将来可能会有所改变，但是对于编译器来说，要将手动编写的比较和交换循环安全地转换为相应的LL/SC循环是非常困难的。其中一个原因是，在stxr和ldxr指令之间可以放置的指令数量和类型有限，而编译器在应用其他优化时并未考虑到这一点。在像比较和交换循环这样的模式仍能被识别出来的时候，表达式将编译为的具体指令还是未知的，使得这成为了对于一般情况来说非常难以实施的优化。\n', '\n', '所以，至少在我们得到更聪明的编译器之前，建议尽可能使用专用的取和修改方法，而不是比较和交换循环。\n', '缓存\n', '\n', '读写内存速度慢，可能会花费与执行数十甚至数百条指令相同的时间。这就是为什么所有性能优良的处理器都实现了缓存，以尽可能避免与相对较慢的内存交互。现代处理器中内存缓存的实现细节非常复杂，部分属于专有的，而且，最重要的是，这对我们编写软件时大部分情况下并不重要。毕竟，缓存这个名字来源于法语单词caché，意为隐藏。然而，理解大多数处理器实现缓存的基本原则在优化软件以提高性能时可以非常有用。（当然，我们不需要借口去了解一个有趣的话题。）\n', '\n', '除非是非常小的微控制器，几乎所有的现代处理器都使用缓存。这样的处理器从不直接与主内存交互，而是将每个读取和写入请求都通过其缓存传送。如果一条指令需要从内存中读取一些东西，处理器会向其缓存请求这些数据。如果数据已经被缓存，那么缓存将快速地响应并提供缓存的数据，避免与主内存交互。否则，它将不得不采取慢路径，此时缓存可能必须向主内存请求相关数据的副本。一旦主内存响应，缓存不仅会最终响应原始的读取请求，而且还会记住这些数据，以便下次请求这些数据时可以更快地响应。如果缓存已满，它会通过丢弃一些它认为最不可能有用的旧数据来腾出空间。\n', '\n', '当一条指令想要向内存写入一些东西时，缓存可以选择保留修改后的数据，而不将其写到主内存。然后，对同一内存地址的任何后续读取请求都将得到一份修改后数据的副本，忽略主内存中过时的数据。它只有在需要将修改的数据从缓存中删除以腾出空间时，才会真的将数据写回主内存。\n', '\n', '在大多数处理器架构中，缓存以64字节的块读取和写入内存，即使只请求了一个字节。这些块通常被称为缓存行。通过缓存包围请求字节的整个64字节块，任何需要访问该块中其他字节的后续指令将不必等待主内存。\n', '缓存一致性\n', '\n', '在现代处理器中，通常有多于一个层级的缓存。第一级缓存，或称之为一级（L1）缓存是最小最快的。它不是与主内存通话，而是与二级（L2）缓存通话，后者要大得多也慢得多。L2缓存可能是与主内存通话的，或者可能有另一个更大更慢的L3缓存---甚至可能有L4缓存。\n', '\n', '增加额外的层次并没有改变它们的工作方式；每个层次都可以独立运行。然而，事情变得有趣的是，当有多个处理器核心，每个都有自己的缓存时。在多核系统中，每个处理器核心通常都有自己的L1缓存，而L2或L3缓存通常与某些或所有其他核心共享。\n', '\n', '在这种条件下，天真的缓存实现会崩溃，因为缓存不能再假设它控制与下一层的所有交互。如果一个缓存接受了一次写入并将某个缓存行标记为已修改，而没有通知其他缓存，那么缓存的状态就可能变得不一致。它的修改后数据不仅在缓存将数据写入到下一层之前都不会对其他核心可用，而且可能会与其他缓存中缓存的不同修改冲突。\n', '\n', '为了解决这个问题，使用了缓存一致性协议。这种协议定义了缓存如何具体操作并与彼此通信以保持一致性状态。使用的具体协议会因架构、处理器模型甚至缓存层级的不同而有所不同。\n', '\n', '我们来讨论两种基本的缓存一致性协议。现代处理器使用了这些的许多变体。\n', '写通协议\n', '\n', "在实现写通缓存一致性协议的缓存中，写入操作不会被缓存，而是立即发送到下一层。其他缓存通过与下一层之间的共享通信通道连接，这意味着它们可以观察到其他缓存与下一层的通信。当一个缓存观察到一个它当前缓存的地址的写入操作时，它马上会丢弃或更新自身的缓存行以保持一致性。\n", '\n', '使用该协议，缓存中永远不会包含处于修改状态下的缓存行。虽然这简化了许多事情，但它抵消了对于写入操作的缓存带来的任何好处。当仅针对读取进行优化时，这可能是一个很好的选择。\n', 'MESI协议\n', '\n', 'MESI缓存一致性协议的名字源自它为缓存行定义的四种可能状态：修改、独家、共享和无效。修改（M）用于包含已被修改但尚未写入内存（或下一级缓存）的数据的缓存行。独家（E）用于包含未修改数据的缓存行，这些数据不在任何其他缓存（在同一级别）中缓存。共享（S）用于未被修改的缓存行，这些缓存行可能也出现在一个或多个其他（同级）缓存中。无效（I）用于未使用的（空的或丢弃的）缓存行，这些缓存行不包含任何有用的数据。\n', '\n', '使用该协议的缓存与在同一级别的所有其他缓存进行通信。它们互相发送更新和请求，使其可能保持彼此的一致性。\n', '\n', '当一个缓存获得一个它尚未缓存的地址的请求，也称为缓存未命中，它不会立即从下一层请求。相反，它首先会问同级别的其他缓存是否有此缓存行可用。如果它们中没有一个拥有，那么缓存将继续从（较慢的）下一层请求地址，并将所得新缓存行标记为独家（E）。当这个缓存行然后被写入操作修改时，缓存可以在不通知其他的情况下将状态改变为修改（M），因为它知道其他的没有缓存同一缓存行。\n', '\n', '在请求一个已经在其他缓存中得到的缓存行时，结果是一个共享（S）的缓存行，直接从其他缓存（多个）获得。如果缓存行处于修改（M）状态，它将首先被写入（或清除）到下一层，然后在将其改为共享（S）并分享它。如果它处于独家（E）状态，它将立即改为共享（S）。\n', '\n', '如果缓存需要独家而不是共享的访问（例如，因为它将在之后修改数据），那么其他缓存将不会保持共享（S）状态的缓存行，而是通过将其改为无效（I）来完全丢弃它。在这种情况下，得到的是一个独家（E）的缓存行。\n', '\n', '如果缓存需要对它已经在共享（S）状态下得到的缓存行进行独家访问，它只需要告诉其他的丢弃缓存行，然后将其升级到独家（E）。\n', '\n', '有这个协议的好几个变体。例如，MOESI协议增加了一个额外的状态以允许在不立即向下一层写入的情况下分享修改后的数据，MESIF协议使用一个额外的状态来决定哪个缓存响应一个在多个缓存中都有的共享缓存行的请求。现代处理器通常使用更复杂、专有的缓存一致性协议。\n', '对性能的影响\n', '\n', '尽管缓存对我们大部分是隐藏的，缓存行为对我们的原子操作的性能可以产生重大影响。让我们试着测量一下其中的一些影响。\n', '\n', '测量单个原子操作的速度非常棘手，因为它们非常快。为了能获得一些有用的数字，我们必须重复一个操作，例如，十亿次，并测量总体所需的时间。例如，我们可以试图测量十亿次载入操作需要的时间，如下所示：\n', '\n', 'static A: AtomicU64 = AtomicU64::new(0);\n', '\n', 'fn main() {\n', '    let start = Instant::now();\n', '    for _ in 0..1_000_000_000 {\n', '        A.load(Relaxed);\n', '    }\n', '    println!("{:?}", start.elapsed());\n', '}\n', '\n', '不幸的是，这并不按预期工作。\n', '\n', '当使用启用了优化的运行（例如，cargo run --release或rustc -O）运行此时，我们会看到计时异常低。发生了什么事是，编译器足够聪明去理解我们没有使用载入的值，因此它决定完全优化这个"不必要的"循环。\n', '\n', '为了避免这种情况，我们可以使用特殊的std::hint::black_box函数。这个函数接收任何类型的参数，然后原样返回，什么都不做。这个函数的特殊之处在于，编译器会尽力不对函数的作用做任何假设；它将该函数视为一个可以做任何事情的"黑箱"。\n', '\n', '我们可以用这个函数来避免那些可能使基准测试无用的优化。在这个情况下，我们可以传递载入操作的结果给black_box()来阻止任何假设我们不实际需要载入的值的优化。但是这还不够，因为编译器可能假设A总是零，使得载入操作变得无关紧要。为了避免这种情况，我们可以在开始时传递对A的引用给black_box()，因此编译器不再假设只有一个线程在访问A。毕竟，它必须假设black_box(&A)可能已在别的线程中与A进行交互。\n', '\n', '让我们试试看：\n', '\n', 'use std::hint::black_box;\n', '\n', 'static A: AtomicU64 = AtomicU64::new(0);\n', '\n', 'fn main() {\n', '    black_box(&A); // 新增！\n', '    let start = Instant::now();\n', '    for _ in 0..1_000_000_000 {\n', '        black_box(A.load(Relaxed)); // 新增！\n', '    }\n', '    println!("{:?}", start.elapsed());\n', '}\n', '\n', '在多次运行时，输出会有一些波动，但在一个不太新的x86-64计算机上，它似乎会给出大约300毫秒的结果。\n', '\n', '为了看到任何缓存效果，我们将在后台线程上生成一个与原子变量交互的程序。这样，我们可以看看它是否会影响主线程的载入操作。\n', '\n', '首先，让我们在后台线程上尝试只用载入操作，如下所示：\n', '\n', 'static A: AtomicU64 = AtomicU64::new(0);\n', '\n', 'fn main() {\n', '    black_box(&A);\n', '\n', '    thread::spawn(|| { // 新的！\n', '        loop {\n', '            black_box(A.load(Relaxed));\n', '        }\n']