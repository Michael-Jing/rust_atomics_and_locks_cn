['第2章. 原子操作\n', '\n', '单词"atomic"来源于希腊语词汇 ἄτομος，意思是"不可分割的"，代表着无法被切割为更小片段的事物。在计算机科学中，它被用来描述一个不可分割的操作：要么全部完成，要么还未发生。\n', '\n', '正如我们在第一章中"借用和数据竞争"所提到的，多线程并行读取和修改同一变量通常会导致未定义行为。然而，原子操作确实允许不同线程安全地读取和修改同一个变量。由于这样的操作是不可分割的，它要么在其他操作之前完全发生，要么在其他操作之后完全发生，避免了未定义的行为。后续在第7章，我们将详解这在硬件层面是如何实现的。\n', '\n', '原子操作是涉及多线程的所有事物的主要构建块。所有其他并发原语，如互斥和条件变量，都是使用原子操作进行实现。\n', '\n', '在Rust语言中，原子操作被实现为在std::sync::atomic中的标准原子类型的方法。他们的名字都以Atomic开头，比如AtomicI32或AtomicUsize。哪些可用取决于硬件架构和有时是操作系统，但几乎所有的平台都提供至少到指针大小的所有原子类型。\n', '\n', '与大多数类型不同，它们允许通过共享引用(例如，&AtomicU8)进行修改。这得益于内部可变性，我们在第1章的"内部可变性"中进行了讨论。\n', '\n', '所有可用的原子类型都有相同的接口，用于存储和加载，原子性的"获取并修改"操作，以及一些更高级的"比较并交换"方法。我们将在本章的其余部分详细讨论它们。\n', '\n', '但是，在我们深入了解不同的原子操作之前，我们需要简单了解一下被称为内存排序的概念：\n', '\n', '每个原子操作都带有一个类型为std::sync::atomic::Ordering的参数，它决定了我们获取操作相对排序的保证。最简单，保证最少的变体是Relaxed。尽管Relaxed仍然保证了单一原子变量的一致性，但不承诺关于不同变量之间操作的相对顺序的任何事情。\n', '\n', '这意味着，两个线程可能会看到不同变量上的操作发生在不同的顺序。例如，如果一个线程先写入一个变量，然后很快写入第二个变量，另一个线程可能看到这两个操作发生的顺序是相反的。\n', '\n', '在本章中，我们只会关注这不是问题的用例，并简单地在所有地方使用Relaxed，而不深入详细的讨论。我们会在第三章中讨论所有关于内存排序和其他可用内存排序的细节。\n', '原子性加载和存储操作\n', '\n', '我们将介绍的前两个原子操作是最基本的操作：加载和存储。它们的函数签名如下，以AtomicI32为例：\n', '\n', '实现 AtomicI32 {\n', '    pub fn load(&self, ordering: Ordering) -> i32;\n', '    pub fn store(&self, value: i32, ordering: Ordering);\n', '}\n', '\n', 'load方法原子性地加载存储在原子变量中的值，store方法原子性地在其中存储一个新值。注意，尽管store方法修改了值，但是它接受的是共享引用(&T)而不是独占引用(&mut T)。\n', '\n', '我们来看看这两种方法的一些实际用例。\n', '示例：停止标志\n', '\n', '第一个示例使用一个AtomicBool来设定一个停止标志。这样一个标志被用来通知其他线程要停止运行。\n', '\n', '使用std::sync::atomic::AtomicBool;\n', '使用std::sync::atomic::Ordering::Relaxed;\n', '\n', 'fn main() {\n', '    静态 STOP: AtomicBool = AtomicBool::new(false);\n', '\n', '    // 创建一个线程来做工作。\n', '    let background_thread = thread::spawn(|| {\n', '        while !STOP.load(Relaxed) {\n', '            some_work();\n', '        }\n', '    });\n', '\n', '    // 使用主线程来监听用户输入。\n', '    for line in std::io::stdin().lines() {\n', '        match line.unwrap().as_str() {\n', '            "help" => println!("commands: help, stop"),\n', '            "stop" => break,\n', '            cmd => println!("unknown command: {cmd:?}"),\n', '        }\n', '    }\n', '\n', '    // 告知后台线程需要停止。\n', '    STOP.store(true, Relaxed);\n', '\n', '    // 等待后台线程完成。\n', '    background_thread.join().unwrap();\n', '}\n', '\n', '在这个例子中，后台线程反复运行some_work()，而主线程允许用户输入一些命令来与程序进行交互。在这个简单的例子中，唯一有用的命令是stop用来停止程序。\n', '\n', '要让后台线程停止，使用原子的STOP布尔型来将这个条件通告给后台线程。当前台线程读到stop命令时，它设置标志为true，这个值在每一次新迭代前都会被后台线程检查。主线程使用join方法等待后台线程完成当前的迭代。\n', '\n', '只要后台线程能定期检查这个标志，这个简单的解决方案就能很好的工作。如果它在some_work() stuck了很长时间，可能会导致停止命令与程序退出之间的无法接受的延迟。\n', '示例：进度报告\n', '\n', '在我们的下一个示例中，我们在后台线程上逐个处理100个项目，而主线程会定期向用户提供进度更新，如下所示：\n', '\n', 'use std::sync::atomic::AtomicUsize;\n', '\n', 'fn main() {\n', '    let num_done = AtomicUsize::new(0);\n', '\n', '    thread::scope(|s| {\n', '        // 一个在后台处理所有100个项目的线程。\n', '        s.spawn(|| {\n', '            for i in 0..100 {\n', '                process_item(i); // 假设这需要一些时间。\n', '                num_done.store(i + 1, Relaxed);\n', '            }\n', '        });\n', '\n', '        // 主线程每秒钟显示一次状态更新。\n', '        loop {\n', '            let n = num_done.load(Relaxed);\n', '            if n == 100 { break; }\n', '            println!("Working.. {n}/100 done");\n', '            thread::sleep(Duration::from_secs(1));\n', '        }\n', '    });\n', '\n', '    println!("Done!");\n', '}\n']['\n', '这次，我们使用限定作用范围的线程（第一章中的"Scoped Threads"），这个线程将自动为我们处理线程的连接，并且允许我们借用局部变量。\n', '\n', '每次后台线程处理完一个项目后，它会将处理过的项目数存储在AtomicUsize中。同时，主线程将这个数字显示给用户，以告知他们进度，大约每秒一次。一旦主线程看到所有100个项目都已处理完毕，它就会退出范围，这会隐式地加入后台线程，并通知用户所有操作都已完成。\n', '同步\n', '\n', '一旦处理完最后一个项目，主线程可能需要等待整整一秒才能知道，这在结束时引入了不必要的延迟。为解决此问题，我们可以使用线程停靠（第一章中的"Thread Parking"）在有可能感兴趣的新信息出现时唤醒主线程。\n', '\n', '下面是相同的例子，但现在使用的是thread::park_timeout而不是thread::sleep:\n', '\n', 'fn main() {\n', '    let num_done = AtomicUsize::new(0);\n', '\n', '    let main_thread = thread::current();\n', '\n', '    thread::scope(|s| {\n', '        // 后台线程处理所有100个项目。\n', '        s.spawn(|| {\n', '            for i in 0..100 {\n', '                process_item(i); // 假设这需要一些时间。\n', '                num_done.store(i + 1, Relaxed);\n', '                main_thread.unpark(); // 唤醒主线程。\n', '            }\n', '        });\n', '\n', '        // 主线程显示状态更新。\n', '        loop {\n', '            let n = num_done.load(Relaxed);\n', '            if n == 100 { break; }\n', '            println!("正在工作.. 完成了{n}/100");\n', '            thread::park_timeout(Duration::from_secs(1));\n', '        }\n', '    });\n', '\n', '    println!("完成了!");\n', '}\n', '\n', '并没有太多改变。我们通过thread::current()获取了主线程的句柄，现在由后台线程在每次状态更新后解除主线程的停靠。现在，主线程使用park_timeout而不是sleep，这样它就可以被中断了。\n', '\n', '现在，任何状态更新都会立即报告给用户，同时每秒重复最后一次更新，以显示该程序仍在运行。\n', '示例：延迟初始化\n', '\n', '在我们进一步探讨更高级的原子操作之前，最后一个例子是关于延迟初始化。\n', '\n', '假设有一个值x，我们从文件中读取它，从操作系统中获取它，或以其他方式计算它，预期在程序运行期间是恒定的。可能x是操作系统的版本，或是总内存量，或是tau的400位数字。对于这个例子，这并不重要。\n', '\n', '由于我们不期望它会改变，我们可以只在第一次需要它的时候请求或计算它，并记住结果。第一个需要它的线程将不得不计算该值，但是它可以将它存储在一个原子静态变量中，使其对所有线程（包括后续如果还需要它的自身线程）可用。\n', '\n', '让我们看看这样一个例子。为了让事情简单，我们假设x绝不是零，因此我们可以在它被计算之前把零作为占位符使用。\n', '\n', '使用std::sync::atomic::AtomicU64;\n', '\n', 'fn get_x() -> u64 {\n', '    static X: AtomicU64 = AtomicU64::new(0);\n', '    let mut x = X.load(Relaxed);\n', '    if x == 0 {\n', '        x = calculate_x();\n', '        X.store(x, Relaxed);\n', '    }\n', '    x\n', '}\n', '\n', '第一个调用get_x()的线程会检查静态变量X，看到它仍然是零，计算它的值，并将结果存回静态变量中以供将来使用。后来，任何对get_x()的调用都会看到静态变量中的值是非零的，而且会立即返回它，而不再计算它。\n', '\n', '然而，如果第二个线程在第一个线程仍在计算x的时候调用get_x()，第二个线程也会看到零并且也会并行计算x。其中一个线程将最终覆盖另一个线程的结果，取决于哪个线程最先完成。这就是所谓的竞态。不是数据竞态，那是未定义行为，在Rust中除非使用unsafe，否则不可能发生，但仍然是一场有不可预知胜者的竞争。\n', '\n', '由于我们期望x是恒定的，所以谁赢得竞态并不重要，因为结果将始终是相同的。取决于我们预期calculate_x()需要多少时间，这可能是一个非常好或非常糟的策略。\n', '\n', '如果预计calculate_x()需要很长时间，那么最好让线程在第一个线程仍在初始化X时等待，以避免不必要地浪费处理器时间。你可以使用条件变量或线程停靠（第一章中的"Waiting: Parking and Condition Variables"）来实现这一点，但这对于一个小例子来说迅速变得太复杂了。Rust标准库通过std::sync::Once和std::sync::OnceLock提供了这个功能，所以通常没有必要自己实现它们。\n', '取和修改操作\n', '\n', '现在我们已经看到了load和store操作的一些基本用例，让我们转向更有趣的操作：取和修改操作。这些操作会修改原子变量，但同时也会加载（取出）原来的值，作为一个单独的原子操作。\n', '\n', '最常用的是fetch_add和fetch_sub，它们分别执行加法和减法。其他一些可用的操作是fetch_or和fetch_and，用于位操作，而fetch_max和fetch_min可以用来保持运行中的最大或最小值。\n', '\n', '它们的函数签名如下，以AtomicI32为例：\n', '\n', 'impl AtomicI32 {\n', '    pub fn fetch_add(&self, v: i32, ordering: Ordering) -> i32;\n', '    pub fn fetch_sub(&self, v: i32, ordering: Ordering) -> i32;\n', '    pub fn fetch_or(&self, v: i32, ordering: Ordering) -> i32;\n', '    pub fn fetch_and(&self, v: i32, ordering: Ordering) -> i32;\n', '    pub fn fetch_nand(&self, v: i32, ordering: Ordering) -> i32;\n', '    pub fn fetch_xor(&self, v: i32, ordering: Ordering) -> i32;\n', '    pub fn fetch_max(&self, v: i32, ordering: Ordering) -> i32;\n', '    pub fn fetch_min(&self, v: i32, ordering: Ordering) -> i32;\n', '    pub fn swap(&self, v: i32, ordering: Ordering) -> i32; // "fetch_store"\n', '}\n', '\n', '唯一的例外是简单地存储一个新值的操作，不管原来的值是什么。它没有被称为fetch_store，而是被称为swap。\n', '\n', '这是一个快速演示，显示fetch_add是如何返回操作之前的值的：\n', '\n', 'use std::sync::atomic::AtomicI32;\n', '\n', 'let a = AtomicI32::new(100);\n', 'let b = a.fetch_add(23, Relaxed);\n', 'let c = a.load(Relaxed);\n', '\n', 'assert_eq!(b, 100);\n']
['assert_eq!(c, 123);\n', '\n', 'fetch_add操作将a从100增加到123，但返回给我们的是旧值100。任何后续操作都会看到123的值。\n', '\n', '这些操作的返回值并不总是相关的。如果你只需要应用操作到原子值，但对值本身不感兴趣，那么完全可以忽略返回值。\n', '\n', '需要牢记的一点是，fetch_add和fetch_sub实现了溢出的循环行为。将值增加到最大可表示值会循环并导致出现最小可表示值。这与常规整数上的加法和减法操作符的行为不同，后者在溢出时会在调试模式下产生恐慌。\n', '\n', '在"比较和交换操作"中，我们将看到如何用溢出检查进行原子加法。\n', '\n', '但首先，让我们来看看这些方法的一些实际使用案例。\n', '示例：从多线程进行进度汇报\n', '\n', '在"示例：进度汇报"中，我们使用了AtomicUsize来报告后台线程的进度。如果我们将工作分散至例如四个线程，每个处理25个项，那么我们需要知道所有四个线程的进度。\n', '\n', '我们可以为每个线程使用一个独立的AtomicUsize，并在主线程中全部加载它们并求和，但更简单的解决方案是使用一个单独的AtomicUsize来跟踪所有线程处理项的总数。\n', '\n', '为了使这种方法起作用，我们不能再使用store方法了，因为它会覆盖其他线程的进度。相反，我们可以使用一个原子加操作来在每个处理项后增加计数器。\n', '\n', '让我们更新"示例：进度汇报"中的例子，将工作分散到四个线程上：\n', '\n', 'fn main() {\n', '    let num_done = &AtomicUsize::new(0);\n', '\n', '    thread::scope(|s| {\n', '        //四个后台线程来处理全部的100个项，每个处理25个。\n', '        for t in 0..4 {\n', '            s.spawn(move || {\n', '                for i in 0..25 {\n', '                    process_item(t * 25 + i); // 假设这需要一些时间。\n', '                    num_done.fetch_add(1, Relaxed);\n', '                }\n', '            });\n', '        }\n', '\n', '        // 主线程每秒显示一次状态更新。\n', '        loop {\n', '            let n = num_done.load(Relaxed);\n', '            if n == 100 { break; }\n', '            println!("Working.. {n}/100 done");\n', '            thread::sleep(Duration::from_secs(1));\n', '        }\n', '    });\n', '\n', '    println!("Done!");\n', '}\n', '\n', '有些东西已经改变了。最重要的是，我们现在创建了四个后台线程而不是一个，并使用fetch_add而不是store来修改num_done原子变量。\n', '\n', '更隐蔽的是，我们现在使用移动闭包的方式对后台线程进行操作，而且num_done现在是一个引用。这和我们使用fetch_add无关，但与我们在一个循环中创建四个线程有关。这个闭包捕获t以知道它是四个线程中的哪一个，因此是否在项0，25，50，或75开始。没有move关键字，闭包将尝试通过引用捕获t。这是不被允许的，因为它只在循环期间短暂存在。\n', '\n', '作为移动闭包，它将移动（或复制）捕获，而不是借用它们，这样就可以得到t的副本。因为它还捕获了num_done，所以我们将该变量改为引用，因为我们仍然希望借用相同的AtomicUsize。需要注意的是，原子类型并不实现Copy trait，所以如果我们试图将一个移动到不止一个线程，我们将得到一个错误。\n', '\n', '除了闭合捕获的细微差别，使用fetch_add的更改非常简单。我们不知道线程将按照何种顺序增加num_done，但由于加法是原子的，我们不必担心任何事情，可以确保当所有线程完成时，它将正好是100。\n', '示例：统计数据\n', '\n', '继续通过原子来报告其他线程在做什么的概念，让我们扩展我们的例子，也收集和报告处理一个项所花费的时间的一些统计数据。\n', '\n', '除了num_done，我们还添加了两个原子变量total_time和max_time，用于跟踪处理项所花费的时间。我们将使用这些来报告平均和峰值处理时间。\n', '\n', 'fn main() {\n', '    let num_done = &AtomicUsize::new(0);\n', '    let total_time = &AtomicU64::new(0);\n', '    let max_time = &AtomicU64::new(0);\n', '\n', '    thread::scope(|s| {\n', '        // 四个后台线程处理全部的100个项，每个处理25个。\n', '        for t in 0..4 {\n', '            s.spawn(move || {\n', '                for i in 0..25 {\n', '                    let start = Instant::now();\n', '                    process_item(t * 25 + i); // 假设这需要一些时间。\n', '                    let time_taken = start.elapsed().as_micros() as u64;\n', '                    num_done.fetch_add(1, Relaxed);\n', '                    total_time.fetch_add(time_taken, Relaxed);\n', '                    max_time.fetch_max(time_taken, Relaxed);\n', '                }\n', '            });\n', '        }\n', '\n', '        // 主线程每秒显示一次状态更新。\n', '        loop {\n', '            let total_time = Duration::from_micros(total_time.load(Relaxed));\n', '            let max_time = Duration::from_micros(max_time.load(Relaxed));\n', '            let n = num_done.load(Relaxed);\n', '            if n == 100 { break; }\n', '            if n == 0 {\n', '                println!("Working.. 没有完成任何工作");\n', '            } else {\n', '                println!(\n', '                    "正在工作.. 完成了{n}/100, 平均时间{:?}, 峰值{:?}",\n', '                    total_time / n as u32,\n', '                    max_time,\n', '                );\n', '            }\n', '            thread::sleep(Duration::from_secs(1));\n', '        }\n', '    });\n', '\n', '    println!("完成!");\n']['}\n', '\n', '后台线程现在使用Instant::now()和Instant::elapsed()来测量它们在process_item()中花费的时间。使用原子加法操作将微秒数加到total_time上，使用原子取最大值操作来跟踪max_time中的最高测量值。\n', '\n', '主线程将总时间除以已处理项目的数量，得到平均处理时间，然后一起报告峰值时间（来自max_time）。\n', '\n', '由于这三个原子变量是单独更新的，可能主线程在线程增加num_done后，但在更新total_time之前，就已经加载了值，导致平均值被低估。更微妙的是，由于松散的内存排序不保证操作的相对顺序如何从另一个线程看到，即使暂时看到了total_time的新更新值，仍然可以看到num_done的旧值，导致对平均值的高估。\n', '\n', '在我们的例子中，这两个都不是大问题。可能发生的最糟糕的情况是用户短暂地报告了不准确的平均值。\n', '\n', '如果我们想避免这种情况，我们可以将这三个统计放入一个互斥锁中。然后，我们会在更新这三个数字时短暂锁定这个互斥锁，这些数字本身就不必再是原子的。这实际上将三次更新变成了一个原子操作，但代价是锁定和解锁一个互斥锁，可能临时阻塞线程。\n', '例子：ID分配\n', '\n', '让我们继续讲述一个实际需要使用fetch_add返回值的用例。\n', '\n', '假设我们需要一个函数，allocate_new_id()，每次调用它都会返回一个新的唯一数字。我们可能会使用这些数字来标识我们的程序中的任务或其他事物；需要通过一些小的、可以容易地在线程之间存储和传递的东西来唯一地标识，比如一个整数。\n', '\n', '实现这个函数使用fetch_add变得非常简单：\n', '\n', '使用 std::sync::atomic::AtomicU32;\n', '\n', 'fn allocate_new_id() -> u32 {\n', '    静态 NEXT_ID: AtomicU32 = AtomicU32::new(0);\n', '    NEXT_ID.fetch_add(1, Relaxed)\n', '}\n', '\n', '我们只需要跟踪下一个要给出的数字，并在每次加载时递增它。第一个调用者会得到一个0，第二个会得到一个1，以此类推。\n', '\n', '唯一的问题是在溢出时的包装行为。第4,294,967,296次呼叫将会使32位整数溢出，使得下一次呼叫将返回0。\n', '\n', '这是否是一个问题取决于用例：它被调用的频率有多高，如果数字不唯一，可能会发生什么样的最糟糕的情况？虽然这看起来是一个巨大的数字，现代计算机可以轻松地在几秒钟内执行我们的函数这么多次。如果内存安全依赖于这些数字的唯一性，我们上面的实现是不可以接受的。\n', '\n', '为了解决这个问题，我们可以尝试让函数在被调用太多次的时候引起恐慌，像这样：\n', '\n', '// 这个版本有问题。\n', 'fn allocate_new_id() -> u32 {\n', '    静态 NEXT_ID: AtomicU32 = AtomicU32::new(0);\n', '    让id = NEXT_ID.fetch_add(1, Relaxed);\n', '    断言!(id < 1000, "太多的IDs!");\n', '    id\n', '}\n', '\n', '现在，assert语句将在一千次呼叫后引发恐慌。然而，这发生在原子加法操作已经发生，意味着当我们恐慌时，NEXT_ID已经加到了1001。如果另一个线程然后调用这个函数，它会将它增加到1002然后恐慌，依此类推。虽然它可能需要显著更长的时间，但是我们在NEXT_ID溢出到零后的4294966296次恐慌后，会遇到同样的问题。\n', '\n', '有三种常见的解决这个问题的方法。第一种是不要恐慌，而是在溢出时完全中止进程。std::process::abort函数将中止整个进程，排除任何可能继续调用我们函数的可能性。虽然在进程中止可能需要一段短暂的时间，函数仍然可以被其他线程调用，但在程序真正中止之前，这种情况发生数十亿次的可能性是可以忽略不计的。\n', '\n', '事实上，这就是如何在标准库中实现的Arc::clone()的溢出检查，以防你不知不觉中克隆了usize::MAX次。在一个64位的计算机上，这可能需要数百年，但如果isize只有32位，那么几秒钟就可以实现。\n', '\n', '处理溢出的第二种方法是使用fetch_sub在恐慌前先减少计数器，像这样：\n', '\n', 'fn allocate_new_id() -> u32 {\n', '    静态 NEXT_ID: AtomicU32 = AtomicU32::new(0);\n', '    let id = NEXT_ID.fetch_add(1, Relaxed);\n', '    if id >= 1000 {\n', '        NEXT_ID.fetch_sub(1, Relaxed);\n', '        panic!("太多的IDs!");\n', '    }\n', '    id\n', '}\n', '\n', '当多个线程同时执行此函数时，计数器可能会短暂地增加到1000以上，但这受到活动线程数量的限制。我们可以合理地假设，即使在fetch_add和fetch_sub之间的短暂时刻，也绝对不会有数亿个活动的线程。\n', '\n', '这就是如何处理标准库中thread::scope实现中运行的线程数量的溢出。\n', '\n', '处理溢出的第三种方法可以说是唯一真正正确的方法，因为它阻止了如果遭遇溢出的话添加的执行。然而，我们不能用我们到目前为止见过的原子操作来实现这一点。对此，我们需要比较和交换操作，我们接下来将探讨。\n', '比较和交换操作\n', '\n', '最先进和最灵活的原子操作是比较和交换操作。这个操作检查原子值是否等于给定的值，只有在这种情况下，才将其替换为新值，所有这些都作为一个单一的原子操作进行。它将返回先前的值，并告诉我们它是否替换了它。\n', '\n', '它的签名比我们到目前为止看到的签名稍微复杂一些。以AtomicI32为例，它看起来像这样：\n', '\n', 'impl AtomicI32 {\n', '    pub fn compare_exchange(\n', '        &self,\n', '        expected: i32,\n', '        new: i32,\n', '        success_order: Ordering,\n', '        failure_order: Ordering\n', '    ) -> Result<i32, i32>;\n', '}\n', '\n', '忽略内存排序一会儿，它基本上与以下实现相同，只是所有的操作都作为一个不可分割的原子操作进行：\n', '\n', 'impl AtomicI32 {\n', '    pub fn compare_exchange(&self, expected: i32, new: i32) -> Result<i32, i32> {\n', '        // 实际上，加载、比较和存储，\n', '        // 都作为一个单一的原子操作进行。\n', '        let v = self.load();\n', '        if v == expected {\n', '            // Value is as expected.\n', '            // Replace it and report success.\n', '            self.store(new);\n', '            Ok(v)\n', '        } else {\n', '            // The value was not as expected.\n', '            // Leave it untouched and report failure.\n', '            Err(v)\n', '        }\n', '    }\n', '}\n']
['\n', '利用这个，我们可以从一个原子变量加载一个值，进行任何我们想要的计算，然后只有在原子变量在此期间没有改变的情况下，才存储新计算出的值。如果我们把这个放在一个循环中，以便在它改变时重试，我们可以用这个来实现所有其他的原子操作，使得它成为最通用的一个。\n', '\n', '为了证明，我们来增加一个AtomicU32的值，而不使用fetch_add，只是为了看看compare_exchange在实践中是如何被使用的：\n', '\n', 'fn increment(a: &AtomicU32) {\n', '    let mut current = a.load(Relaxed); 1\n', '    loop {\n', '        let new = current + 1; 2\n', '        match a.compare_exchange(current, new, Relaxed, Relaxed) { 3\n', '            Ok(_) => return, 4\n', '            Err(v) => current = v, 5\n', '        }\n', '    }\n', '}\n', '\n', '1\t\n', '\n', '首先，我们加载a的当前值。\n', '2\t\n', '\n', '我们计算我们想要存储在a中的新值，不考虑其他线程可能并发修改a。\n', '3\t\n', '\n', '我们使用compare_exchange更新a的值，但只有在它的值仍然是我们之前加载的值时才这样做。\n', '4\t\n', '\n', '如果a的确还是和以前一样，那么现在我们的新值就替换了，我们就完成了。\n', '5\t\n', '\n', '如果a和以前不一样，那么必定有其他线程在我们加载值之后的短暂时间内改变了它。compare_exchange操作给我们a的改变值，我们将使用那个值再次尝试。从加载到更新的瞬间间隔是如此短暂，以至于它不太可能循环超过几次。\n', '\n', '如果原子变量在加载操作后从某个值A改变为B，然后在compare_exchange操作前又改回A，即使原子变量在此期间被改变（并且又被改回），它仍然会成功。在许多情况下，如我们的增量例子，这不是问题。然而，有某些涉及到原子指针的算法，这可能会成为问题。这就是所谓的ABA问题。\n', '\n', '除了compare_exchange，还有一个类似的方法名为compare_exchange_weak。区别在于，即使原子值匹配预期值，弱版本可能仍有时候不会改变值，并返回一个Err。在某些平台上，这种方法可以更有效地实现，应该在对偶然的比较和交换失败的后果微不足道的情况下进行优选，如我们上面的增量函数。在第7章中，我们会深入探讨低级细节，找出为什么弱版本可能更有效。\n', '例子：无溢出的ID分配\n', '\n', '现在，让我们回到我们在“示例：ID分配”中的overflow问题。\n', '\n', '为了防止将NEXT_ID增大到一定的极限，以防溢出，我们可以使用compare_exchange实现具有上界的原子加法。运用这个想法，我们可以制作一个版本的allocate_new_id，它永远处理溢出正确，即使在在实际上不可能的情况：\n', '\n', 'fn allocate_new_id() -> u32 {\n', '    static NEXT_ID: AtomicU32 = AtomicU32::new(0);\n', '    let mut id = NEXT_ID.load(Relaxed);\n', '    loop {\n', '        assert!(id < 1000, "too many IDs!");\n', '        match NEXT_ID.compare_exchange_weak(id, id + 1, Relaxed, Relaxed) {\n', '            Ok(_) => return id,\n', '            Err(v) => id = v,\n', '        }\n', '    }\n', '}\n', '\n', '现在我们在修改NEXT_ID之前就检查并panic，保证它永远不会被增加超过1000，这使得溢出变得不可能。我们现在可以把上限从1000提高到u32::MAX，而不用担心它可能被增加超过限制的边缘情况。\n', 'Fetch-Update\n', '\n', '原子类型有一个方便的方法叫做fetch_update，用于比较-交换循环模式。它相当于一个加载操作，后面跟着一个重复计算和compare_exchange_weak的循环，就像我们上面做的一样。\n', '\n', '使用它，我们可以用一行代码实现我们的allocate_new_id函数：\n', '\n', '    NEXT_ID.fetch_update(Relaxed, Relaxed,\n', '        |n| n.checked_add(1)).expect("too many IDs!")\n', '\n', '查看该方法的文档以获得详细信息。\n', '\n', '在这本书中，我们不会使用fetch_update方法，这样我们可以专注于各个原子操作。\n', '例子：懒一次性初始化\n', '\n', '在“例子：懒初始化”中，我们看了一个对常量值进行懒初始化的例子。我们做了一个函数，这个函数在第一次调用时懒惰地初始化一个值，但在后来的调用中重用它。当多个线程在第一次调用期间并发运行函数时，不止一个线程可能会执行初始化，它们将以不可预测的顺序覆盖彼此的结果。\n', '\n', '这对于我们期望的常量值，或者我们不关心改变值的情况是可以的。然而，也有那些需要每次函数调用都返回同一个值的用例，尽管我们每次都初始化一个不同的值。\n', '\n', '比如，设想一个函数get_key()，它返回一个只生成一次的随机生成的键。它可能是一个用于与程序通信的加密密钥，这个密钥需要在每次运行程序时都是唯一的，但在一个进程中是常量。\n', '\n', '这意味着我们不能在生成一个键后简单地使用一个存储操作，因为这可能会覆盖几时刻前由其他线程生成的键，导致两个线程使用不同的键。相反，我们可以使用compare_exchange来确保我们只有在没有其他线程已经这样做的情况下才存储键，否则我们会扔掉我们的键，并使用存储的键替代。\n', '\n', '这是一个实现这个想法的方法：\n', '\n', 'fn get_key() -> u64 {\n', '    static KEY: AtomicU64 = AtomicU64::new(0);\n', '    let key = KEY.load(Relaxed);\n', '    if key == 0 {\n', '        let new_key = generate_random_key(); 1\n', '        match KEY.compare_exchange(0, new_key, Relaxed, Relaxed) { 2\n', '            Ok(_) => new_key, 3\n', '            Err(k) => k, 4\n', '        }\n', '    } else {\n', '        key\n', '    }\n', '}\n', '\n', '1\t\n', '\n', '我们只有在KEY尚未初始化时才生成新的键。\n', '2\t\n', '\n', '我们用我们新生成的键替换KEY，但只有在它仍然是零的时候才这样做。\n', '3\t\n', '\n']['如果我们把零换成我们的新密钥，我们就返回新生成的密钥。新的get_key()调用将返回现在存储在KEY中的相同的新密钥。\n', '4\t\n', '\n', '如果我们在初始化KEY之前输给了另一个线程，我们就忘记我们新生成的密钥，而使用KEY中的密钥。\n', '\n', '这是一个比较交换的适当使用场合的好例子。我们不在循环中进行比较和交换操作，我们也不希望在操作意外失败时返回零。\n', '\n', '如"例子：延迟初始化"所述，如果generate_random_key()需要很长时间，那么在初始化期间阻止线程可能更有意义，以避免可能浪费时间生成不会被使用的密钥。Rust标准库通过std::sync::Once和std::sync::OnceLock提供了这样的功能。\n', '总结\n', '\n', '    原子操作是不可分割的；它们要么完全完成，要么还没发生。\n', '\n', '    Rust中的原子操作是通过std::sync::atomic中的原子类型完成的，如AtomicI32。\n', '\n', '    并非所有的原子类型都适用于所有的平台。\n', '\n', '    当涉及多个变量时，原子操作的相对顺序很棘手。第三章有更多内容。\n', '\n', '    简单的加载和存储对于非常基本的线程间通信非常有用，如停止标志和状态报告。\n', '\n', '    可以用比赛的方式进行懒惰的初始化，而不会引发数据竞争。\n', '\n', '    获取和修改操作允许一小组基本的原子修改，这在多线程修改同一个原子变量时特别有用。\n', '\n', '    原子的加法和减法在溢出时无声地回环。\n', '\n', '    比较和交换操作是最灵活和最一般的，也是制作任何其他原子操作的构建块。\n', '\n', '    一个弱的比较-交换操作可以更有效率。 \n']